{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#datamate-documentation","title":"Datamate Documentation","text":"<p>Datamate is a lightweight data and configuration management framework in Python, tailored to support research in machine-learning science. It uses the filesystem as memory, providing a numpy-like interface to HDF5 files organized in hierarchical structures.</p>"},{"location":"#example","title":"Example","text":"<p>The following example demonstrates how to set up an experiment directory, store experiment configuration in _meta.yaml, and store arrays as HDF5 files without boilerplate code. More examples can be found in the examples section.</p> <pre><code>import datamate\nimport numpy as np\n\n# Set up experiment directory\ndatamate.set_root_dir(\"./experiments\")\n\n# Set up experiment configuration\nconfig = {\n    \"model\": \"01\",\n    \"date\": \"2024-03-20\",\n    \"optimizer\": \"Adam\",\n    \"learning_rate\": 0.001,\n    \"n_epochs\": 100,\n    \"description\": \"Setting the learning rate to 0.001\"\n}\n\n# Set up experiment directory at ./experiments/vision_study/model_01\n# and store configuration in _meta.yaml\nexp = datamate.Directory(\"vision_study/model_01\", config)\n\n# Store arrays as HDF5 files\nexp.images = np.random.rand(100, 64, 64)  # stored as images.h5\nexp.responses = np.zeros((100, 1000))     # stored as responses.h5\n\n# Verify that the experiment data is set up\nprint(exp)\n\ndef train(exp: datamate.Directory):\n    \"\"\"Train a model using the experiment's config and data.\"\"\"\n    # Set up optimizer using config\n    optimizer = get_optimizer(exp.config.optimizer, lr=exp.config.learning_rate)\n\n    losses = []\n    # Training loop using config parameters\n    for epoch in range(exp.config.n_epochs):\n        # ... training code ...\n\n        # Cache results in memory to avoid high IO overhead\n        losses.append(loss)\n\n    # Store results back in experiment directory outside of the training loop\n    exp.losses = np.array(losses)  # creates losses.h5\n\n# Run training\ntrain(exp)\n\n# Access results\nmean_loss = exp.losses.mean()  # compute mean loss\n</code></pre>"},{"location":"#main-features","title":"Main Features","text":"<p>The main features of <code>datamate</code> are:</p> <ul> <li>Filesystem as memory with numpy-like interface</li> <li>Hierarchical data organization</li> <li>Automatic path handling and resolution with pathlib</li> <li>Array storage in HDF5 format</li> <li>Parallel read/write operations</li> <li>Configuration-based compilation and access of data</li> <li>Configuration management in YAML files</li> <li>Configuration comparison and diffing</li> <li>Pandas DataFrame integration</li> <li>Directory structure visualization (tree view)</li> <li>Basic experiment status tracking</li> </ul>"},{"location":"#installation","title":"Installation","text":"<p><code>pip install datamate</code></p>"},{"location":"#tutorials","title":"Tutorials","text":"<ul> <li>datamate Examples</li> <li>Parallel read/write operations</li> </ul>"},{"location":"#api-reference","title":"API Reference","text":"<p>For detailed information about Datamate\u2019s components and functions, please refer to our API Reference section.</p>"},{"location":"#related-projects","title":"Related Projects","text":"<p><code>datamate</code> was co-developed with the flyvis project, which is a complex usage example of <code>datamate</code>.</p> <p>artisan is the original framework that inspired <code>datamate</code>.</p>"},{"location":"#getting-help","title":"Getting Help","text":"<p>If you have any questions or encounter any issues, please check our FAQ or Contributing pages for more information.</p>"},{"location":"acknowledgements/","title":"Acknowledgements","text":""},{"location":"acknowledgements/#development","title":"Development","text":"<p>Datamate was developed with love in free time and in relation to work done at the Macke Lab at the University of T\u00fcbingen and at the Turaga Lab at Janelia Research Campus. See related projects for more information.</p>"},{"location":"acknowledgements/#citation","title":"Citation","text":"<p>If you use Datamate in your research, please cite:</p> <pre><code>Citation information pending JOSS paper submission\n</code></pre>"},{"location":"acknowledgements/#license","title":"License","text":"<p>MIT License</p> <p>Copyright \u00a9 2024 Janne K. Lappalainen, Mason McGill, Srinivas C. Turaga, Jakob H. Macke</p>"},{"location":"contribute/","title":"Contributing","text":"<p>Contribute to this project by submitting any issue on GitHub. Suggestions for improving the code, bug reports, and questions are welcome. We will attend to issues and pull requests as time allows and appreciate any feedback!</p>"},{"location":"contribute/#developer-guide","title":"Developer Guide","text":"<p>To get involved, please read this guide.</p>"},{"location":"contribute/#project-setup","title":"Project Setup","text":"<p>This project uses Python and is built with setuptools. It requires Python 3.6 or higher.</p>"},{"location":"contribute/#installation","title":"Installation","text":"<p>To set up the development environment:</p> <ol> <li> <p>Clone the repository:    <pre><code>git clone https://github.com/flyvis/datamate.git\ncd datamate\n</code></pre></p> </li> <li> <p>Create and activate a virtual environment:    <pre><code>python -m venv venv\nsource venv/bin/activate\n</code></pre></p> </li> <li> <p>Install the package with development dependencies:    <pre><code>pip install -e \".[dev]\"\n</code></pre></p> </li> </ol>"},{"location":"contribute/#development-tools","title":"Development Tools","text":""},{"location":"contribute/#code-formatting-and-linting","title":"Code Formatting and Linting","text":"<p>We use the following tools for code quality:</p> <ul> <li>Ruff: For linting and code formatting. Configuration is in <code>pyproject.toml</code>.</li> <li>Pre-commit: To run checks before committing.</li> </ul> <p>To set up pre-commit hooks:</p> <pre><code>pre-commit install\n</code></pre>"},{"location":"contribute/#testing","title":"Testing","text":"<p>We use pytest for testing. Run tests with:</p> <pre><code>pytest\n</code></pre>"},{"location":"contribute/#documentation","title":"Documentation","text":"<p>Documentation is built using MkDocs. To build and serve the documentation locally:</p> <pre><code>mkdocs serve\n</code></pre> <p>To build the documentation, see the docs readme.</p>"},{"location":"contribute/#dependency-management","title":"Dependency Management","text":"<ul> <li>Main dependencies are listed in <code>pyproject.toml</code> under <code>[project.dependencies]</code>.</li> <li>Development dependencies are under <code>[project.optional-dependencies.dev]</code>.</li> <li>Documentation dependencies are under <code>[project.optional-dependencies.docs]</code>.</li> </ul> <p>To install all dependencies including development and documentation:</p> <pre><code>pip install -e \".[dev,docs]\"\n</code></pre>"},{"location":"contribute/#version-management","title":"Version Management","text":"<p>This project uses <code>setuptools_scm</code> for versioning. The version is automatically derived from git tags.</p>"},{"location":"contribute/#project-structure","title":"Project Structure","text":"<ul> <li><code>datamate/</code>: Main package directory</li> <li><code>tests/</code>: Test files</li> <li><code>docs/</code>: Documentation files</li> <li><code>examples/</code>: Example scripts and notebooks</li> </ul>"},{"location":"contribute/#contribution-guidelines","title":"Contribution Guidelines","text":"<ol> <li>Fork the repository and create your branch from <code>main</code>.</li> <li>Ensure the test suite passes by running <code>pytest</code>.</li> <li>Make sure your code follows the project\u2019s style guide (enforced by Ruff).</li> <li>Update documentation as necessary.</li> <li>Create a pull request with a clear description of your changes.</li> </ol>"},{"location":"faq/","title":"Frequently asked questions","text":"<p>Please contribute to this FAQ by submitting an issue on GitHub.</p>"},{"location":"release/","title":"Release Process","text":""},{"location":"release/#prerequisites","title":"Prerequisites","text":"<ol> <li> <p>Ensure all tests pass: <pre><code>pytest\n</code></pre></p> </li> <li> <p>Update and verify the documentation: Follow the instructions in the readme to update and verify the documentation. The deployment to github can be done last or via workflow.</p> </li> <li> <p>Install required tools: <pre><code>python -m pip install build twine\n</code></pre></p> </li> </ol>"},{"location":"release/#release-steps","title":"Release Steps","text":"<ol> <li>Test PyPi before committing (optional)</li> </ol> <p>One can create the wheel and upload it to Test PyPi before committing to develop the package. This can be useful to test if the installation will work before commiting to a version number and push to the remote repository. However, the wheels that are uploaded to Test PyPi cannot be deleted so one should probably do this sparingly and not use version numbers one wants to reserve for the actual release.</p>"},{"location":"release/#upload-to-test-pypi","title":"Upload to Test PyPi","text":"<pre><code># Clean previous builds\nrm -rf dist/\n\n# Set version temporarily for this session manually (change version number)\nexport SETUPTOOLS_SCM_PRETEND_VERSION=0.0.0.dev7\n\n# Now build and test\npython -m build\n\n# Upload to Test PyPI first\npython -m twine upload --repository testpypi dist/*\n</code></pre>"},{"location":"release/#test-installation","title":"Test Installation","text":"<p>In a clean environment, run these sporadic tests to verify the installation: <pre><code># Install in clean environment to test (change version number)\npython -m pip install --index-url https://test.pypi.org/simple/ --extra-index-url https://pypi.org/simple/ flyvis==0.0.0.dev7\n\n# Test installation\nflyvis download-pretrained\nflyvis train --help\nflyvis train-single --help\npython -c \"from flyvis import Network; n = Network()\"\npython -c \"from flyvis import EnsembleView; e = EnsembleView('flow/0000')\"\n\n\n# Test custom configuration\nflyvis init-config\n# Add custom_syn_strength.yaml to flyvis_config/network/edge_config/syn_strength/\ncat &gt; flyvis_config/network/edge_config/syn_strength/custom_syn_strength.yaml &lt;&lt; 'EOL'\ndefaults:\n  - /network/edge_config/syn_strength/syn_strength@_here_\n  - _self_\n\nscale: 1.0\nEOL\n# Run training and check if custom config is loaded correctly\nflyvis train-single --config-dir $(pwd)/flyvis_config network/edge_config/syn_strength=custom_syn_strength ensemble_and_network_id=0 task_name=flow delete_if_exists=true 2&gt;&amp;1 | while read line; do\n    echo \"$line\"\n    if [[ \"$line\" == *\"'syn_strength': {'type': 'SynapseCountScaling'\"* &amp;&amp; \"$line\" == *\"'scale': 1.0\"* ]]; then\n        echo \"Found custom scale parameter in config!\"\n        pkill -P $$\n        break\n    fi\ndone\n# Delete custom config\nrm -rf flyvis_config\n\n# Delete installation and downloaded models\npip uninstall flyvis -y\n\n# When done testing, unset it\nunset SETUPTOOLS_SCM_PRETEND_VERSION\n</code></pre></p>"},{"location":"release/#commit-changes","title":"Commit Changes","text":"<p>Commit all open changes to the repository.</p>"},{"location":"release/#update-changelog","title":"Update Changelog","text":"<ul> <li>Append entry in <code>CHANGELOG.md</code> with new version number</li> <li>Include all notable changes under appropriate sections, e.g.,</li> <li>Breaking</li> <li>Features</li> <li>Documentation</li> <li>Infrastructure</li> <li>Distribution</li> <li>Bug Fixes</li> </ul> <pre><code>git add CHANGELOG.md\ngit commit -m \"docs: add changelog for v1.1.2\"\n</code></pre>"},{"location":"release/#create-and-push-tag","title":"Create and Push Tag","text":"<pre><code># Create annotated tag using changelog\ngit tag -a v1.1.2 -F CHANGELOG.md\n\n# Push to both remotes\ngit push origin main\ngit push origin v1.1.2\ngit push public_repo main\ngit push public_repo v1.1.2\n</code></pre>"},{"location":"release/#build-and-upload-to-pypi","title":"Build and Upload to PyPI","text":"<pre><code># Clean previous builds\nrm -rf dist/\n\n# Set version temporarily for this session manually\nexport SETUPTOOLS_SCM_PRETEND_VERSION=1.1.2\n\n# Build package\npython -m build\n\n# Upload to PyPI\npython -m twine upload dist/*\n</code></pre>"},{"location":"release/#create-github-release","title":"Create GitHub Release","text":"<ul> <li>Go to GitHub releases page</li> <li>Create new release using the tag</li> <li>Copy changelog entry into release description</li> </ul>"},{"location":"release/#post-release","title":"Post-release","text":"<ol> <li>Verify package can be installed from PyPI: <pre><code>python -m pip install flyvis\n</code></pre></li> </ol>"},{"location":"release/#check-documentation-is-updated-on-the-documentation-website","title":"Check documentation is updated on the documentation website","text":""},{"location":"release/#version-numbering","title":"Version Numbering","text":"<p>We follow semantic versioning (MAJOR.MINOR.PATCH): - MAJOR: Breaking changes - MINOR: New features (backwards compatible) - PATCH: Bug fixes</p>"},{"location":"release/#notes","title":"Notes","text":"<ul> <li>Always test on Test PyPI before releasing to PyPI</li> <li>Ideally CI checks pass before releasing</li> <li>Keep both origin and public_repo remotes in sync</li> </ul>"},{"location":"examples/01a_datamate_examples/","title":"<code>datamate</code> Examples","text":"<p>Basic examples demonstrating <code>datamate</code> functionality.</p>          Image: \"Mouse neurons labeled with fluorescent tags\" by Stephen J Smith (2007), licensed under         CC BY 3.0."},{"location":"examples/01a_datamate_examples/#filesystem-as-memory","title":"Filesystem as memory","text":"<pre><code>from pathlib import Path\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom datamate import Directory, set_root_dir\n\n%load_ext autoreload\n%autoreload 2\n</code></pre> <pre><code># we set the root directory\nroot_dir = Path(\".\") / \"data\"\nset_root_dir(root_dir)\n</code></pre> <pre><code># we erase data from earlier execution of this notebook -- ignore this cell\nif root_dir.exists():\n    import shutil\n\n    shutil.rmtree(root_dir)\n</code></pre> <pre><code># we create a Directory instance\ncell_measurements = Directory()\ncell_measurements\n</code></pre> <pre><code>Directory_0000/\n    (empty)\n</code></pre> <p>We \u2018measure\u2019 cell attributes: identity, x- and y-coordinates, and colors.</p> <pre><code># we store data by setting attributes\nn_cells = 100\ncell_measurements.cell_id = np.arange(n_cells)\ncell_measurements.x = np.random.normal(0, 1, size=n_cells)\ncell_measurements.y = np.random.normal(0, 1, size=n_cells)\ncell_measurements.colors = np.random.rand(n_cells, 3)\n</code></pre> <pre><code># we verify files with the tree-view method\n# (automatically called)\ncell_measurements\n</code></pre> <pre><code>Directory_0000/ - Last modified: January 17, 2025 19:36:16\n\u251c\u2500\u2500 _meta.yaml\n\u251c\u2500\u2500 cell_id.h5\n\u251c\u2500\u2500 colors.h5\n\u251c\u2500\u2500 x.h5\n\u2514\u2500\u2500 y.h5\n\ndisplaying: 1 directory, 5 files, 2 levels.\n</code></pre> <pre><code># we access data as attributes\nplt.scatter(cell_measurements.x, cell_measurements.y, c=cell_measurements.colors, s=10)\nplt.xlabel(\"cell location in x\")\nplt.ylabel(\"cell location in y\")\nplt.title(f\"Locations and colors of {n_cells} cells\")\n</code></pre> <pre><code>Text(0.5, 1.0, 'Locations and colors of 100 cells')\n</code></pre> <p></p> <pre><code># we index h5-arrays from disk without fully loading them to reduce memory load\nstart_cell_id = 0\nend_cell_id = 50\nplt.scatter(\n    cell_measurements.x[start_cell_id:end_cell_id],\n    cell_measurements.y[start_cell_id:end_cell_id],\n    c=cell_measurements.colors[start_cell_id:end_cell_id],\n    s=10,\n)\nplt.xlabel(\"cell location in x\")\nplt.ylabel(\"cell location in y\")\nplt.title(f\"Locations and colors of {end_cell_id - start_cell_id} cells\")\n</code></pre> <pre><code>Text(0.5, 1.0, 'Locations and colors of 50 cells')\n</code></pre> <p></p> <pre><code># we use the directory name to point to the same directory again\ncell_measurements = Directory(\"Directory_0000\")\n\n# works also with specifying the root directory\n# cell_measurements = Directory(root_dir / \"Directory_0000\")\n\ncell_measurements\n</code></pre> <pre><code>Directory_0000/ - Last modified: January 17, 2025 19:36:16\n\u251c\u2500\u2500 _meta.yaml\n\u251c\u2500\u2500 cell_id.h5\n\u251c\u2500\u2500 colors.h5\n\u251c\u2500\u2500 x.h5\n\u2514\u2500\u2500 y.h5\n\ndisplaying: 1 directory, 5 files, 2 levels.\n</code></pre>"},{"location":"examples/01a_datamate_examples/#hierarchical-data-organization","title":"Hierarchical data organization","text":"<pre><code># we navigate upwards on the filesystem hierarchy\ncell_measurements.parent\n</code></pre> <pre><code>data/ - Last modified: January 17, 2025 19:36:16\n\u2514\u2500\u2500 Directory_0000/\n    \u251c\u2500\u2500 _meta.yaml\n    \u251c\u2500\u2500 cell_id.h5\n    \u251c\u2500\u2500 colors.h5\n    \u251c\u2500\u2500 x.h5\n    \u2514\u2500\u2500 y.h5\n\ndisplaying: 2 directories, 5 files, 2 levels.\n</code></pre> <pre><code># we navigate upwards twice\ncell_measurements.parent.parent\n</code></pre> <pre><code>examples/ - Last modified: January 17, 2025 19:36:16\n\u251c\u2500\u2500 .gitignore\n\u251c\u2500\u2500 01a_datamate_examples.ipynb\n\u251c\u2500\u2500 01b_parallel_read_and_write.ipynb\n\u2514\u2500\u2500 data/\n    \u2514\u2500\u2500 Directory_0000/\n        ...\n\ndisplaying: 3 directories, 3 files, 2 levels.\n</code></pre> <pre><code># we create a pointer to a child Directory\n# (as long as no file/attribute with this name already exists)\ncell_measurements.connections\n</code></pre> <pre><code>connections/\n    (empty)\n</code></pre> <pre><code># we `measure` a random connectivity matrix\nconnectivity_matrix = np.random.randn(n_cells, n_cells) &gt; 2\nplt.imshow(connectivity_matrix)\nplt.xlabel(\"postsynaptic cell id\")\nplt.ylabel(\"presynaptic cell id\")\nplt.title(\"connectivity matrix\")\n</code></pre> <pre><code>Text(0.5, 1.0, 'connectivity matrix')\n</code></pre> <pre><code># we store the connectivity as graph (i.e. edges) because its sparse\npost_cell_id, pre_cell_id = np.where(connectivity_matrix)\ncell_measurements.connections.pre_cell_id = pre_cell_id\ncell_measurements.connections.post_cell_id = post_cell_id\n</code></pre> <pre><code># the connections are now stored in our directory\ncell_measurements\n</code></pre> <pre><code>Directory_0000/ - Last modified: January 17, 2025 19:36:16\n\u251c\u2500\u2500 _meta.yaml\n\u251c\u2500\u2500 cell_id.h5\n\u251c\u2500\u2500 colors.h5\n\u251c\u2500\u2500 connections/\n\u2502   \u251c\u2500\u2500 _meta.yaml\n\u2502   \u251c\u2500\u2500 post_cell_id.h5\n\u2502   \u2514\u2500\u2500 pre_cell_id.h5\n\u251c\u2500\u2500 x.h5\n\u2514\u2500\u2500 y.h5\n\ndisplaying: 2 directories, 8 files, 2 levels.\n</code></pre> <pre><code># we access them later from the same directory\ncell_measurements.connections\n</code></pre> <pre><code>connections/ - Last modified: January 17, 2025 19:36:16\n\u251c\u2500\u2500 _meta.yaml\n\u251c\u2500\u2500 post_cell_id.h5\n\u2514\u2500\u2500 pre_cell_id.h5\n\ndisplaying: 1 directory, 3 files, 2 levels.\n</code></pre> <pre><code># with attribute-style access to the h5-array\ncell_measurements.connections.pre_cell_id[:]\n</code></pre> <pre><code>array([12, 39, 48, 63, 41, 82, 41, 92,  2, 28, 89, 17, 28, 30, 41, 86, 89,\n        2, 25, 76, 68, 28, 32, 46, 63, 92,  6, 42, 70, 74, 31, 12, 22, 92,\n       97,  5, 31, 45, 75,  1,  8, 57, 85, 96, 21, 27, 79, 75,  3, 21, 67,\n       81, 88, 10, 26, 93, 51, 56, 46, 57, 85, 40, 51, 69,  1, 39, 68,  7,\n       59, 78, 95,  0, 61,  9,  4,  9, 40,  0, 16, 20, 22, 76, 98,  7, 80,\n       87, 24, 53,  7, 66, 85, 26, 35, 68, 16, 42,  3, 16, 31, 52, 10, 20,\n       86, 82, 83, 89, 96, 17, 27, 39, 19, 51, 68, 71,  1, 19, 61, 77, 64,\n       87, 53, 51, 13, 73, 90, 32, 68, 83, 38, 44, 82, 24, 49, 76, 30, 88,\n       41, 61, 20, 61, 76, 81, 84, 89,  2, 36, 45, 52, 69, 71, 76,  1, 42,\n       79, 25, 42, 30, 88, 18, 37, 97, 98, 99, 97, 66,  1, 27, 57, 83, 85,\n       54, 51, 62, 52, 88, 74, 82, 89, 18, 31, 92,  3, 58, 85, 28, 70, 72,\n        9, 20, 44, 65,  5, 22, 41, 90, 96, 19, 27, 69, 84, 37,  1, 11, 45,\n       63, 17, 30, 22, 30, 42, 58, 96])\n</code></pre> <pre><code># or composing strings following the pathlib syntax for your preference\n(cell_measurements / \"connections/pre_cell_id\")[:]\n</code></pre> <pre><code>array([12, 39, 48, 63, 41, 82, 41, 92,  2, 28, 89, 17, 28, 30, 41, 86, 89,\n        2, 25, 76, 68, 28, 32, 46, 63, 92,  6, 42, 70, 74, 31, 12, 22, 92,\n       97,  5, 31, 45, 75,  1,  8, 57, 85, 96, 21, 27, 79, 75,  3, 21, 67,\n       81, 88, 10, 26, 93, 51, 56, 46, 57, 85, 40, 51, 69,  1, 39, 68,  7,\n       59, 78, 95,  0, 61,  9,  4,  9, 40,  0, 16, 20, 22, 76, 98,  7, 80,\n       87, 24, 53,  7, 66, 85, 26, 35, 68, 16, 42,  3, 16, 31, 52, 10, 20,\n       86, 82, 83, 89, 96, 17, 27, 39, 19, 51, 68, 71,  1, 19, 61, 77, 64,\n       87, 53, 51, 13, 73, 90, 32, 68, 83, 38, 44, 82, 24, 49, 76, 30, 88,\n       41, 61, 20, 61, 76, 81, 84, 89,  2, 36, 45, 52, 69, 71, 76,  1, 42,\n       79, 25, 42, 30, 88, 18, 37, 97, 98, 99, 97, 66,  1, 27, 57, 83, 85,\n       54, 51, 62, 52, 88, 74, 82, 89, 18, 31, 92,  3, 58, 85, 28, 70, 72,\n        9, 20, 44, 65,  5, 22, 41, 90, 96, 19, 27, 69, 84, 37,  1, 11, 45,\n       63, 17, 30, 22, 30, 42, 58, 96])\n</code></pre>"},{"location":"examples/01a_datamate_examples/#configuration-based-compilation-of-data","title":"Configuration-based compilation of data","text":"<p>We wrap up the code above into a coherent object that can be configured and compiled to a <code>Directory</code>.</p> <pre><code>from time import sleep\nfrom pathlib import Path\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom datamate import Directory, root\n\ndata_dir = Path(\".\") / \"data\"\n\n\n@root(data_dir)  # this optional decorator defines the root directory\nclass CellMeasurements(Directory):\n\n    def __init__(self, n_cells=100, seed=0):\n        print(\"Loading connectome ...\")\n        sleep(5)\n        np.random.seed(seed)\n\n        # store cell attributes\n        self.cell_id = np.arange(n_cells)\n        self.x = np.random.normal(0, 1, size=n_cells)\n        self.y = np.random.normal(0, 1, size=n_cells)\n        self.colors = np.random.rand(n_cells, 3)\n\n        # store connectivity attributes\n        connectivity_matrix = np.random.randn(n_cells, n_cells)\n        pre_cell_id, post_cell_id = np.where(connectivity_matrix &gt; 2)\n        self.connections.pre_cell_id = pre_cell_id\n        self.connections.post_cell_id = post_cell_id\n        print(\"Stored connectome!\")\n</code></pre> <pre><code># we init 'CellMeasurements'\n# __init__ is only run if a directory of this type and config does not yet exist\ncell_measurements = CellMeasurements()\n</code></pre> <pre><code>Loading connectome ...\n\n\nStored connectome!\n</code></pre> <pre><code># we verify contents written by __init__\ncell_measurements\n</code></pre> <pre><code>CellMeasurements_0000/ - Last modified: January 17, 2025 19:36:21\n\u251c\u2500\u2500 _meta.yaml\n\u251c\u2500\u2500 cell_id.h5\n\u251c\u2500\u2500 colors.h5\n\u251c\u2500\u2500 connections/\n\u2502   \u251c\u2500\u2500 _meta.yaml\n\u2502   \u251c\u2500\u2500 post_cell_id.h5\n\u2502   \u2514\u2500\u2500 pre_cell_id.h5\n\u251c\u2500\u2500 x.h5\n\u2514\u2500\u2500 y.h5\n\ndisplaying: 2 directories, 8 files, 2 levels.\n</code></pre> <pre><code># we verify config written by __init__\ncell_measurements.meta\n</code></pre> <pre><code>Namespace(\n  config = Namespace(type='CellMeasurements', n_cells=100, seed=0),\n  status = 'done'\n)\n</code></pre> <pre><code># we change the seed\n# we automatically get a second directory of the same type (but with different data)\ncell_measurements_2 = CellMeasurements(n_cells=100, seed=42)\n</code></pre> <pre><code>Loading connectome ...\n\n\nStored connectome!\n</code></pre> <pre><code># we verify contents written by __init__\ncell_measurements_2\n</code></pre> <pre><code>CellMeasurements_0001/ - Last modified: January 17, 2025 19:36:26\n\u251c\u2500\u2500 _meta.yaml\n\u251c\u2500\u2500 cell_id.h5\n\u251c\u2500\u2500 colors.h5\n\u251c\u2500\u2500 connections/\n\u2502   \u251c\u2500\u2500 _meta.yaml\n\u2502   \u251c\u2500\u2500 post_cell_id.h5\n\u2502   \u2514\u2500\u2500 pre_cell_id.h5\n\u251c\u2500\u2500 x.h5\n\u2514\u2500\u2500 y.h5\n\ndisplaying: 2 directories, 8 files, 2 levels.\n</code></pre> <pre><code># we verify config written by __init__\ncell_measurements_2.meta\n</code></pre> <pre><code>Namespace(\n  config = Namespace(type='CellMeasurements', n_cells=100, seed=42),\n  status = 'done'\n)\n</code></pre>"},{"location":"examples/01a_datamate_examples/#memory-persistence","title":"Memory persistence","text":"<p>We restart the kernel and retrieve the data quickly later, using the same code and without recomputing.</p> <pre><code>from time import sleep\nfrom pathlib import Path\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom datamate import Directory, root\n\ndata_dir = Path(\".\") / \"data\"\n\n\n@root(data_dir)\nclass CellMeasurements(Directory):\n\n    def __init__(self, n_cells=100, seed=0):\n        print(\"Loading connectome ...\")\n        sleep(5)\n        np.random.seed(seed)\n\n        # store cell attributes\n        self.cell_id = np.arange(n_cells)\n        self.x = np.random.normal(0, 1, size=n_cells)\n        self.y = np.random.normal(0, 1, size=n_cells)\n        self.colors = np.random.rand(n_cells, 3)\n\n        # store connectivity attributes\n        connectivity_matrix = np.random.randn(n_cells, n_cells)\n        pre_cell_id, post_cell_id = np.where(connectivity_matrix &gt; 2)\n        self.connections.pre_cell_id = pre_cell_id\n        self.connections.post_cell_id = post_cell_id\n        print(\"Stored connectome!\")\n</code></pre> <pre><code># fast init because points to the directories with the same type and configuration\ncell_measurements = CellMeasurements(n_cells=100, seed=0)\ncell_measurements_2 = CellMeasurements(n_cells=100, seed=42)\n</code></pre> <pre><code>cell_measurements.config\n</code></pre> <pre><code>Namespace(type='CellMeasurements', n_cells=100, seed=0)\n</code></pre> <pre><code>cell_measurements_2.config\n</code></pre> <pre><code>Namespace(type='CellMeasurements', n_cells=100, seed=42)\n</code></pre>"},{"location":"examples/01a_datamate_examples/#pandas-integration","title":"Pandas integration","text":"<p>We load the h5 data to a pandas dataframe for further processing.</p> <pre><code>cells = cell_measurements.to_df()\nconnections = cell_measurements.connections.to_df()\n</code></pre> <pre><code>cells\n</code></pre> cell_id x y colors 0 0 1.764052 1.883151 [0.961936378547229, 0.29214752679254885, 0.240... 1 1 0.400157 -1.347759 [0.10029394226549782, 0.016429629591474204, 0.... 2 2 0.978738 -1.270485 [0.66991654659091, 0.7851529120231378, 0.28173... 3 3 2.240893 0.969397 [0.5864101661863267, 0.06395526612098112, 0.48... 4 4 1.867558 -1.173123 [0.9774951397444468, 0.8765052453165908, 0.338... ... ... ... ... ... 95 95 0.706573 -0.171546 [0.5887396099702882, 0.9627703198402424, 0.016... 96 96 0.010500 0.771791 [0.6964824307014501, 0.8136786497018634, 0.509... 97 97 1.785870 0.823504 [0.33396486959680916, 0.7908401632274049, 0.09... 98 98 0.126912 2.163236 [0.44203563772992527, 0.5199523745708382, 0.69... 99 99 0.401989 1.336528 [0.09088573203240946, 0.22775950153786095, 0.4... <p>100 rows \u00d7 4 columns</p> <pre><code>connections\n</code></pre> post_cell_id pre_cell_id 0 23 0 1 33 0 2 62 0 3 28 1 4 54 2 ... ... ... 206 8 97 207 35 97 208 9 98 209 81 98 210 97 99 <p>211 rows \u00d7 2 columns</p> <p>We load the meta data into a pandas dataframe.</p> <pre><code>cell_measurements.meta.to_df(name=\"measurements 1\")\n</code></pre> measurements 1 status done config.type CellMeasurements config.n_cells 100 config.seed 0 <pre><code>cell_measurements_2.meta.to_df(name=\"measurements 2\")\n</code></pre> measurements 2 status done config.type CellMeasurements config.n_cells 100 config.seed 42 <p>We tabularize experiment configurations.</p> <pre><code>configs = cell_measurements.meta.to_df(name=\"measurements 1\").join(\n    cell_measurements_2.meta.to_df(name=\"measurements 2\")\n)\nconfigs\n</code></pre> measurements 1 measurements 2 status done done config.type CellMeasurements CellMeasurements config.n_cells 100 100 config.seed 0 42 <p>Or, vice versa, we create a directory from a pandas DataFrame (note, must provide h5py compatible type information):</p> <pre><code>configs\n</code></pre> measurements 1 measurements 2 status done done config.type CellMeasurements CellMeasurements config.n_cells 100 100 config.seed 0 42 <pre><code>dtypes = {\"measurements 1\": \"S50\", \"measurements 2\": \"S50\"}\n</code></pre> <pre><code># we create a directory from the dataframe of configs\ndirectory = Directory.from_df(configs, dtypes, \"experiments_config\")\n</code></pre> <pre><code>directory\n</code></pre> <pre><code>experiments_config/ - Last modified: January 17, 2025 19:36:26\n\u251c\u2500\u2500 _meta.yaml\n\u251c\u2500\u2500 measurements 1.h5\n\u2514\u2500\u2500 measurements 2.h5\n\ndisplaying: 1 directory, 3 files, 2 levels.\n</code></pre> <pre><code>directory.to_df(dtypes={\"measurements 1\": str, \"measurements 2\": str})\n</code></pre> measurements 2 measurements 1 0 done done 1 CellMeasurements CellMeasurements 2 100 100 3 42 0 <p>Alternatively, we seamlessly store and retrieve dataframes via csv files.</p> <pre><code>directory.cells = cell_measurements.to_df()\ndirectory.connections = connections\n</code></pre> <pre><code># we verify the dataframes\ndirectory.cells\n</code></pre> cell_id x y colors 0 0 1.764052 1.883151 [0.961936378547229, 0.29214752679254885, 0.240... 1 1 0.400157 -1.347759 [0.10029394226549782, 0.016429629591474204, 0.... 2 2 0.978738 -1.270485 [0.66991654659091, 0.7851529120231378, 0.28173... 3 3 2.240893 0.969397 [0.5864101661863267, 0.06395526612098112, 0.48... 4 4 1.867558 -1.173123 [0.9774951397444468, 0.8765052453165908, 0.338... ... ... ... ... ... 95 95 0.706573 -0.171546 [0.5887396099702882, 0.9627703198402424, 0.016... 96 96 0.010500 0.771791 [0.6964824307014501, 0.8136786497018634, 0.509... 97 97 1.785870 0.823504 [0.33396486959680916, 0.7908401632274049, 0.09... 98 98 0.126912 2.163236 [0.44203563772992527, 0.5199523745708382, 0.69... 99 99 0.401989 1.336528 [0.09088573203240946, 0.22775950153786095, 0.4... <p>100 rows \u00d7 4 columns</p> <pre><code>directory.connections\n</code></pre> post_cell_id pre_cell_id 0 23 0 1 33 0 2 62 0 3 28 1 4 54 2 ... ... ... 206 8 97 207 35 97 208 9 98 209 81 98 210 97 99 <p>211 rows \u00d7 2 columns</p> <pre><code># we extend the dataframes\ndirectory.extend(\"cells\", cell_measurements_2.to_df())\ndirectory.extend(\"connections\", cell_measurements_2.connections.to_df())\n</code></pre> <pre><code># we verify the dataframes\ndirectory.cells\n</code></pre> cell_id x y colors 0 0 1.764052 1.883151 [0.961936378547229, 0.29214752679254885, 0.240... 1 1 0.400157 -1.347759 [0.10029394226549782, 0.016429629591474204, 0.... 2 2 0.978738 -1.270485 [0.66991654659091, 0.7851529120231378, 0.28173... 3 3 2.240893 0.969397 [0.5864101661863267, 0.06395526612098112, 0.48... 4 4 1.867558 -1.173123 [0.9774951397444468, 0.8765052453165908, 0.338... ... ... ... ... ... 195 95 -1.463515 0.385317 [0.7723183917356393, 0.5201635011119934, 0.852... 196 96 0.296120 -0.883857 [0.5519068387744855, 0.5609379715353863, 0.876... 197 97 0.261055 0.153725 [0.40348286621239704, 0.13401522845064073, 0.0... 198 98 0.005113 0.058209 [0.755137255673619, 0.6203095513534647, 0.7040... 199 99 -0.234587 -1.142970 [0.21296416150891073, 0.13637147558676976, 0.0... <p>200 rows \u00d7 4 columns</p> <pre><code># we verify the dataframes\ndirectory.connections\n</code></pre> post_cell_id pre_cell_id 0 23 0 1 33 0 2 62 0 3 28 1 4 54 2 ... ... ... 437 57 97 438 61 97 439 91 98 440 27 99 441 52 99 <p>442 rows \u00d7 2 columns</p>"},{"location":"examples/01a_datamate_examples/#example-visualize-the-graph","title":"Example: visualize the graph","text":"<pre><code>def visualize_measurements(cell_measurements):\n    try:\n        import networkx as nx\n    except ModuleNotFoundError as e:\n        print(e, \", install networkx to visualize the cell graph structure.\")\n        _input = input(\"install now? yes/no\")\n        if _input == \"yes\":\n            import sys\n            !{sys.executable} -m pip install networkx\n            import networkx as nx\n        else:\n            return\n\n    cells = cell_measurements.to_df()\n    connections = cell_measurements.connections.to_df()\n\n    G = nx.Graph()\n    G.add_nodes_from(cells.cell_id)\n    G.add_edges_from(connections.values)\n    pos = dict(zip(cells[\"cell_id\"].values, cells[[\"x\", \"y\"]].values))\n\n    options = {\n        \"font_size\": 4,\n        \"node_size\": 10,\n        \"node_color\": cell_measurements.colors[:],\n        \"edgecolors\": \"0.5\",\n        \"linewidths\": 0.25,\n        \"width\": 0.25,\n    }\n    nx.draw_networkx(G, pos, **options)\n</code></pre> <pre><code>visualize_measurements(cell_measurements)\n</code></pre> <pre><code>visualize_measurements(cell_measurements_2)\n</code></pre>"},{"location":"examples/01a_datamate_examples/#configuration-comparison-and-diffing","title":"Configuration comparison and diffing","text":"<pre><code># we compare how the `measurements` differ in their configuration\n# (this works with complex nested configurations too)\ncell_measurements.meta.diff(cell_measurements_2.meta)\n</code></pre> <pre><code>Namespace(self=['\u2260config.seed: 0'], other=['\u2260config.seed: 42'])\n</code></pre>"},{"location":"examples/01a_datamate_examples/#directory-structure-visualization-tree-view","title":"Directory structure visualization (tree view)","text":"<pre><code>from datamate import Directory, set_verbosity_level\n\ndata_dir = Path(\".\") / \"data\"\n</code></pre> <pre><code># default: we display 2 levels of the hierarchy and 25 lines\nset_verbosity_level(1)\nDirectory(data_dir)\n</code></pre> <pre><code>data/ - Last modified: January 17, 2025 19:36:26\n\u251c\u2500\u2500 CellMeasurements_0000/\n\u2502   \u251c\u2500\u2500 _meta.yaml\n\u2502   \u251c\u2500\u2500 cell_id.h5\n\u2502   \u251c\u2500\u2500 colors.h5\n\u2502   \u251c\u2500\u2500 connections/\n\u2502   \u2502   ...\n\u2502   \u251c\u2500\u2500 x.h5\n\u2502   \u2514\u2500\u2500 y.h5\n\u251c\u2500\u2500 CellMeasurements_0001/\n\u2502   \u251c\u2500\u2500 _meta.yaml\n\u2502   \u251c\u2500\u2500 cell_id.h5\n\u2502   \u251c\u2500\u2500 colors.h5\n\u2502   \u251c\u2500\u2500 connections/\n\u2502   \u2502   ...\n\u2502   \u251c\u2500\u2500 x.h5\n\u2502   \u2514\u2500\u2500 y.h5\n\u251c\u2500\u2500 Directory_0000/\n\u2502   \u251c\u2500\u2500 _meta.yaml\n\u2502   \u251c\u2500\u2500 cell_id.h5\n\u2502   \u251c\u2500\u2500 colors.h5\n\u2502   \u251c\u2500\u2500 connections/\n\u2502   \u2502   ...\n\u2502   \u251c\u2500\u2500 x.h5\n\u2502   \u2514\u2500\u2500 y.h5\n\u2514\u2500\u2500 experiments_config/\n... length_limit, 25, reached,\ndisplaying: 8 directories, 15 files, 2 levels.\n</code></pre> <pre><code># we display all subdirectories and files\nset_verbosity_level(2)\nDirectory(data_dir)\n</code></pre> <pre><code>data/ - Last modified: January 17, 2025 19:36:26\n\u251c\u2500\u2500 CellMeasurements_0000/\n\u2502   \u251c\u2500\u2500 _meta.yaml\n\u2502   \u251c\u2500\u2500 cell_id.h5\n\u2502   \u251c\u2500\u2500 colors.h5\n\u2502   \u251c\u2500\u2500 connections/\n\u2502   \u2502   \u251c\u2500\u2500 _meta.yaml\n\u2502   \u2502   \u251c\u2500\u2500 post_cell_id.h5\n\u2502   \u2502   \u2514\u2500\u2500 pre_cell_id.h5\n\u2502   \u251c\u2500\u2500 x.h5\n\u2502   \u2514\u2500\u2500 y.h5\n\u251c\u2500\u2500 CellMeasurements_0001/\n\u2502   \u251c\u2500\u2500 _meta.yaml\n\u2502   \u251c\u2500\u2500 cell_id.h5\n\u2502   \u251c\u2500\u2500 colors.h5\n\u2502   \u251c\u2500\u2500 connections/\n\u2502   \u2502   \u251c\u2500\u2500 _meta.yaml\n\u2502   \u2502   \u251c\u2500\u2500 post_cell_id.h5\n\u2502   \u2502   \u2514\u2500\u2500 pre_cell_id.h5\n\u2502   \u251c\u2500\u2500 x.h5\n\u2502   \u2514\u2500\u2500 y.h5\n\u251c\u2500\u2500 Directory_0000/\n\u2502   \u251c\u2500\u2500 _meta.yaml\n\u2502   \u251c\u2500\u2500 cell_id.h5\n\u2502   \u251c\u2500\u2500 colors.h5\n\u2502   \u251c\u2500\u2500 connections/\n\u2502   \u2502   \u251c\u2500\u2500 _meta.yaml\n\u2502   \u2502   \u251c\u2500\u2500 post_cell_id.h5\n\u2502   \u2502   \u2514\u2500\u2500 pre_cell_id.h5\n\u2502   \u251c\u2500\u2500 x.h5\n\u2502   \u2514\u2500\u2500 y.h5\n\u2514\u2500\u2500 experiments_config/\n    \u251c\u2500\u2500 _meta.yaml\n    \u251c\u2500\u2500 cells.csv\n    \u251c\u2500\u2500 connections.csv\n    \u251c\u2500\u2500 measurements 1.h5\n    \u2514\u2500\u2500 measurements 2.h5\n\ndisplaying: 8 directories, 29 files\n</code></pre> <pre><code># we display referenced folder and last modified date\nset_verbosity_level(0)\nDirectory(data_dir)\n</code></pre> <pre><code>data/ - Last modified: January 17, 2025 19:36:26\n</code></pre> <pre><code>set_verbosity_level(2)\n</code></pre>"},{"location":"examples/01a_datamate_examples/#parallel-readwrite-operations","title":"Parallel read/write operations","text":"<p>We start the training loop by running the cells below.</p> <p>We run the jupyter notebook <code>01b_datamate_intro_supplement.ipynb</code> to see how data is simultaneously written and read to the loss.h5 file.</p> <pre><code>from tqdm.auto import tqdm\nfrom time import sleep\nfrom pathlib import Path\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom datamate import Directory, root\n\ndata_dir = Path(\".\") / \"data\"\n\n\n@root(data_dir)\nclass NetworkDir(Directory):\n\n    class Config:\n        tau: float = 200.0\n        sigma: float = 0.1\n\n    def __init__(self, num_iters: int = 100):\n        del self.loss\n        for i in tqdm(range(num_iters), desc=\"Training\"):\n            self.train_iter(i)\n\n    def train_iter(self, iter):\n        self.extend(\n            \"loss\",\n            [np.exp(-iter / self.config.tau) + np.random.rand() * self.config.sigma],\n        )\n        sleep(0.25)\n</code></pre> <pre><code>network_dir = NetworkDir()\nnetwork_dir\n</code></pre> <pre><code>Training:   0%|          | 0/100 [00:00&lt;?, ?it/s]\n\n\n\n\n\nNetworkDir_0000/ - Last modified: January 17, 2025 19:36:27\n\u251c\u2500\u2500 _meta.yaml\n\u2514\u2500\u2500 loss.h5\n\ndisplaying: 1 directory, 2 files\n</code></pre> <pre><code>plt.plot(network_dir.loss[:])\nplt.xlabel(\"iteration\")\nplt.ylabel(\"loss\")\nplt.title(\"Training loss\")\n</code></pre> <pre><code>Text(0.5, 1.0, 'Training loss')\n</code></pre> <p></p> <pre><code># we verify that the directory exists\n\"NetworkDir_0000\" in Directory(data_dir)\n</code></pre> <pre><code>True\n</code></pre> <pre><code># we delete the directory and its contents\n# network_dir.rmtree(\"y\")\n</code></pre> <pre><code># we verify that the directory is deleted\n# \"NetworkDir_0000\" in Directory(data_dir)\n</code></pre> <pre><code>\n</code></pre>"},{"location":"examples/01b_parallel_read_and_write/","title":"Parallel read/write operations","text":""},{"location":"examples/01b_parallel_read_and_write/#parallel-readwrite-operations","title":"Parallel read/write operations","text":"<p>This example requires <code>01a_datamate_intro.ipynb</code> to be run simultaneously.</p> <p>We monitor the <code>Directory</code> called \u201cNetworkDir_0000\u201d from <code>01a_datamate_into</code> to track the training progress.</p> <pre><code>from pathlib import Path\nfrom time import sleep\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport datamate\n\nroot_dir = Path(\".\") / \"data\"\ndatamate.set_root_dir(root_dir)\n</code></pre> <pre><code># we instantiate a pointer to the known Directory\nnetwork_dir = datamate.Directory(\"NetworkDir_0000\")\n</code></pre> <pre><code>/Users/janne/projects/datamate/datamate/directory.py:1352: ConfigWarning: Casting to a new subclass of Directory because \"NetworkDir\" can't be resolved as it is not found inside the current scope of Directory subclasses. This dynamically created subclass allows to view the data without access to the original class definition and methods. If this happens unexpectedly with autoreload enabled in a notebook/IPython session, run `datamate.reset_scope(datamate.Directory)` as a workaround or restart the kernel (background: https://github.com/ipython/ipython/issues/12399).\n  directory = _forward_subclass(type(cls), config)\n</code></pre> <pre><code>network_dir.meta\n</code></pre> <pre><code>Namespace(\n  config = Namespace(type='NetworkDir', tau=200.0, sigma=0.1, num_iters=100),\n  status = 'done'\n)\n</code></pre> <pre><code># we visualize the loss to monitor the training\n\n\ndef watch_loss(network_dir, updates=100):\n    fig = plt.figure()\n    ax = plt.subplot()\n    ax.plot(network_dir.loss[:])\n    ax.set_xlabel(\"iteration\")\n    ax.set_ylabel(\"loss\")\n\n    def update_loss(loss):\n        iters = np.arange(0, len(loss))\n        ax.lines[0].set_data(iters, loss)\n        print(f\"Current loss: {loss[-1]:.2f}\", end=\"\\r\")\n        if loss.any():\n            ymax = np.max(loss)\n            ymin = np.min(loss)\n        ax.axis([0, iters[-1], ymin, ymax])\n\n    while network_dir.meta.status == \"running\":\n        loss = network_dir.loss[:]\n        update_loss(loss)\n        fig.canvas.draw()\n        fig.canvas.flush_events()\n        sleep(0.1)\n        updates -= 1\n</code></pre> <pre><code>%matplotlib notebook\nwatch_loss(network_dir)\n</code></pre> <pre><code>&lt;IPython.core.display.Javascript object&gt;\n</code></pre> <pre><code>\n</code></pre>"},{"location":"reference/context/","title":"Context","text":""},{"location":"reference/context/#datamate.context","title":"datamate.context","text":"<p>This module handles context management and global settings for Directory objects.</p>"},{"location":"reference/context/#datamate.context.set_root_dir","title":"set_root_dir","text":"<pre><code>set_root_dir(root_dir)\n</code></pre> <p>Set the directory in which to search for Directory objects.</p> <p>Parameters:</p> Name Type Description Default <code>root_dir</code> <code>Optional[Path]</code> <p>Path to set as root directory. If None, uses current directory.</p> required Source code in <code>datamate/context.py</code> <pre><code>def set_root_dir(root_dir: Optional[Path]) -&gt; None:\n    \"\"\"Set the directory in which to search for Directory objects.\n\n    Args:\n        root_dir: Path to set as root directory. If None, uses current directory.\n    \"\"\"\n    context.root_dir = Path(root_dir) if root_dir is not None else Path(\".\")\n</code></pre>"},{"location":"reference/context/#datamate.context.get_root_dir","title":"get_root_dir","text":"<pre><code>get_root_dir()\n</code></pre> <p>Return the current Directory search directory.</p> <p>Returns:</p> Name Type Description <code>Path</code> <code>Path</code> <p>Current root directory, defaults to current directory if not set.</p> Source code in <code>datamate/context.py</code> <pre><code>def get_root_dir() -&gt; Path:\n    \"\"\"Return the current Directory search directory.\n\n    Returns:\n        Path: Current root directory, defaults to current directory if not set.\n    \"\"\"\n    return getattr(context, \"root_dir\", Path(\".\"))\n</code></pre>"},{"location":"reference/context/#datamate.context.root","title":"root","text":"<pre><code>root(root_dir=None, precedence=2)\n</code></pre> <p>Decorates a callable to fix its individual root directory.</p> <p>Parameters:</p> Name Type Description Default <code>root_dir</code> <code>Union[str, Path, NoneType]</code> <p>Root directory that will be set at execution of the callable.</p> <code>None</code> <code>precedence</code> <code>Literal[1, 2, 3]</code> <p>Determines the precedence of this root setting.</p> <ul> <li><code>1</code>: Lowest - global and context settings override this</li> <li><code>2</code>: Medium - overrides global but not context settings</li> <li><code>3</code>: Highest - overrides both global and context settings</li> </ul> <code>2</code> <p>Returns:</p> Name Type Description <code>callable</code> <code>callable</code> <p>Decorated function or class.</p> Example <pre><code>@root(\"/path/to/this/individual/dir\", precedence=3)\nclass MyDirectory(Directory):\n    pass\n\ndir = MyDirectory(...)\nassert dir.path.parent == \"/path/to/this/individual/dir\"\n</code></pre> <p>Raises:</p> Type Description <code>ValueError</code> <p>If decorator is applied to anything other than function or class.</p> Source code in <code>datamate/context.py</code> <pre><code>def root(\n    root_dir: Union[str, Path, NoneType] = None, precedence: Literal[1, 2, 3] = 2\n) -&gt; callable:\n    \"\"\"Decorates a callable to fix its individual root directory.\n\n    Args:\n        root_dir: Root directory that will be set at execution of the callable.\n        precedence: Determines the precedence of this root setting.\n\n            - `1`: Lowest - global and context settings override this\n            - `2`: Medium - overrides global but not context settings\n            - `3`: Highest - overrides both global and context settings\n\n    Returns:\n        callable: Decorated function or class.\n\n    Example:\n        ```python\n        @root(\"/path/to/this/individual/dir\", precedence=3)\n        class MyDirectory(Directory):\n            pass\n\n        dir = MyDirectory(...)\n        assert dir.path.parent == \"/path/to/this/individual/dir\"\n        ```\n\n    Raises:\n        ValueError: If decorator is applied to anything other than function or class.\n    \"\"\"\n\n    def decorator(callable):\n        if inspect.isfunction(callable):\n\n            @functools.wraps(callable)\n            def function(*args, **kwargs):\n                _root_dir = get_root_dir()\n                within_context = getattr(context, \"within_root_context\", False)\n\n                if root_dir is not None and (\n                    precedence == 3\n                    or (precedence == 2 and not within_context)\n                    or precedence == 1\n                    and not within_context\n                ):\n                    set_root_dir(root_dir)\n\n                _return = callable(*args, **kwargs)\n                set_root_dir(_root_dir)\n                return _return\n\n            return function\n        elif inspect.isclass(callable):\n            new = callable.__new__\n\n            @functools.wraps(callable)\n            def function(*args, **kwargs):\n                _root_dir = get_root_dir()\n                within_context = getattr(context, \"within_root_context\", False)\n\n                if root_dir is not None and (\n                    precedence == 3\n                    or (precedence == 2 and not within_context)\n                    or precedence == 1\n                    and not within_context\n                ):\n                    set_root_dir(root_dir)\n\n                _return = new(*args, **kwargs)\n                set_root_dir(_root_dir)\n                return _return\n\n            callable.__new__ = function\n\n            return callable\n        else:\n            raise ValueError(\"Decorator can only be applied to functions or classes.\")\n\n    return decorator\n</code></pre>"},{"location":"reference/context/#datamate.context.set_root_context","title":"set_root_context","text":"<pre><code>set_root_context(root_dir=None)\n</code></pre> <p>Set root directory within a context and revert after.</p> <p>Parameters:</p> Name Type Description Default <code>root_dir</code> <code>Union[str, Path, NoneType]</code> <p>Temporary root directory to use within the context.</p> <code>None</code> Example <pre><code>with set_root_context(dir):\n    Directory(config)\n</code></pre> Note <p>Takes precedence over all other methods to control the root directory.</p> Source code in <code>datamate/context.py</code> <pre><code>@contextmanager\ndef set_root_context(root_dir: Union[str, Path, NoneType] = None) -&gt; None:\n    \"\"\"Set root directory within a context and revert after.\n\n    Args:\n        root_dir: Temporary root directory to use within the context.\n\n    Example:\n        ```python\n        with set_root_context(dir):\n            Directory(config)\n        ```\n\n    Note:\n        Takes precedence over all other methods to control the root directory.\n    \"\"\"\n    _root_dir = get_root_dir()\n    set_root_dir(root_dir)\n    context.within_root_context = True\n    try:\n        yield\n    finally:\n        set_root_dir(_root_dir)\n        context.within_root_context = False\n</code></pre>"},{"location":"reference/context/#datamate.context.enforce_config_match","title":"enforce_config_match","text":"<pre><code>enforce_config_match(enforce)\n</code></pre> <p>Enforce error if configs are not matching.</p> <p>Parameters:</p> Name Type Description Default <code>enforce</code> <code>bool</code> <p>Whether to enforce config matching.</p> required Note <p>Configs are compared when initializing a directory from an existing path and configuration.</p> Source code in <code>datamate/context.py</code> <pre><code>def enforce_config_match(enforce: bool) -&gt; None:\n    \"\"\"Enforce error if configs are not matching.\n\n    Args:\n        enforce: Whether to enforce config matching.\n\n    Note:\n        Configs are compared when initializing a directory from an existing path\n        and configuration.\n    \"\"\"\n    context.enforce_config_match = enforce\n</code></pre>"},{"location":"reference/context/#datamate.context.set_verbosity_level","title":"set_verbosity_level","text":"<pre><code>set_verbosity_level(level)\n</code></pre> <p>Set verbosity level of representation for Directory objects.</p> <p>Parameters:</p> Name Type Description Default <code>level</code> <code>Literal[0, 1, 2]</code> <p>Verbosity level where:</p> <ul> <li><code>0</code>: Only top level directory name and last modified date</li> <li><code>1</code>: Maximum 2 levels and 25 lines</li> <li><code>2</code>: All directories and files</li> </ul> required Source code in <code>datamate/context.py</code> <pre><code>def set_verbosity_level(level: Literal[0, 1, 2]) -&gt; None:\n    \"\"\"Set verbosity level of representation for Directory objects.\n\n    Args:\n        level: Verbosity level where:\n\n            - `0`: Only top level directory name and last modified date\n            - `1`: Maximum 2 levels and 25 lines\n            - `2`: All directories and files\n    \"\"\"\n    context.verbosity_level = level\n</code></pre>"},{"location":"reference/context/#datamate.context.check_size_on_init","title":"check_size_on_init","text":"<pre><code>check_size_on_init(enforce)\n</code></pre> <p>Switch size warning on/off.</p> <p>Parameters:</p> Name Type Description Default <code>enforce</code> <code>bool</code> <p>Whether to check directory size on initialization.</p> required Note <p>Checking the size of a directory is slow, therefore this should be used only consciously.</p> Source code in <code>datamate/context.py</code> <pre><code>def check_size_on_init(enforce: bool) -&gt; None:\n    \"\"\"Switch size warning on/off.\n\n    Args:\n        enforce: Whether to check directory size on initialization.\n\n    Note:\n        Checking the size of a directory is slow, therefore this should be used\n        only consciously.\n    \"\"\"\n    context.check_size_on_init = enforce\n</code></pre>"},{"location":"reference/context/#datamate.context.delete_if_exists","title":"delete_if_exists","text":"<pre><code>delete_if_exists(enable=True)\n</code></pre> <p>Delete directory if it exists within a context and revert after.</p> <p>Parameters:</p> Name Type Description Default <code>enable</code> <code>bool</code> <p>Whether to enable directory deletion.</p> <code>True</code> Example <pre><code>with delete_if_exists():\n    Directory(config)\n</code></pre> Source code in <code>datamate/context.py</code> <pre><code>@contextmanager\ndef delete_if_exists(enable: bool = True) -&gt; None:\n    \"\"\"Delete directory if it exists within a context and revert after.\n\n    Args:\n        enable: Whether to enable directory deletion.\n\n    Example:\n        ```python\n        with delete_if_exists():\n            Directory(config)\n        ```\n    \"\"\"\n    context.delete_if_exists = enable\n    try:\n        yield\n    finally:\n        context.delete_if_exists = False\n</code></pre>"},{"location":"reference/diff/","title":"Diff","text":""},{"location":"reference/diff/#datamate.diff","title":"datamate.diff","text":"<p>This module provides functionality for comparing Directory objects.</p>"},{"location":"reference/diff/#datamate.diff.DirectoryDiff","title":"DirectoryDiff","text":"<p>Compare two directories for equality or differences.</p> <p>Attributes:</p> Name Type Description <code>directory1</code> <p>First directory to compare.</p> <code>directory2</code> <p>Second directory to compare.</p> <code>name1</code> <p>Name identifier for the first directory.</p> <code>name2</code> <p>Name identifier for the second directory.</p> <p>Examples:</p> <pre><code>dir1 = Directory(\"path/to/dir1\")\ndir2 = Directory(\"path/to/dir2\")\ndiff = DirectoryDiff(dir1, dir2)\n\n# Check if directories are equal\nis_equal = diff.equal()\n\n# Get differences\ndifferences = diff.diff()\n</code></pre> Source code in <code>datamate/diff.py</code> <pre><code>class DirectoryDiff:\n    \"\"\"Compare two directories for equality or differences.\n\n    Attributes:\n        directory1: First directory to compare.\n        directory2: Second directory to compare.\n        name1: Name identifier for the first directory.\n        name2: Name identifier for the second directory.\n\n    Examples:\n        ```python\n        dir1 = Directory(\"path/to/dir1\")\n        dir2 = Directory(\"path/to/dir2\")\n        diff = DirectoryDiff(dir1, dir2)\n\n        # Check if directories are equal\n        is_equal = diff.equal()\n\n        # Get differences\n        differences = diff.diff()\n        ```\n    \"\"\"\n\n    def __init__(\n        self,\n        directory1: \"Directory\",\n        directory2: \"Directory\",\n        name1: str = None,\n        name2: str = None,\n    ):\n        self.directory1 = directory1\n        self.directory2 = directory2\n        self.name1 = name1 or self.directory1.path.name\n        self.name2 = name2 or self.directory2.path.name\n\n    def equal(self, fail: bool = False) -&gt; bool:\n        \"\"\"Return True if the directories are equal.\n\n        Args:\n            fail: If True, raise AssertionError when directories differ.\n\n        Returns:\n            bool: True if directories are equal, False otherwise.\n\n        Raises:\n            AssertionError: If directories differ and `fail=True`.\n        \"\"\"\n        try:\n            assert_equal_directories(self.directory1, self.directory2)\n            return True\n        except AssertionError as e:\n            if fail:\n                raise AssertionError from e\n            return False\n\n    def diff(self, invert: bool = False) -&gt; Dict[str, List[str]]:\n        \"\"\"Return differences between the directories.\n\n        Args:\n            invert: If True, swap the order of comparison.\n\n        Returns:\n            Dict[str, List[str]]: Dictionary containing differences, keyed by directory names.\n        \"\"\"\n        if invert:\n            return self._diff_directories(self.directory2, self.directory1)\n        return self._diff_directories(self.directory1, self.directory2)\n\n    def config_diff(self) -&gt; Dict[str, List[str]]:\n        \"\"\"Return the differences between the configurations of the directories.\"\"\"\n        return self.directory1.config.diff(\n            self.directory2.config, name1=self.name1, name2=self.name2\n        )\n\n    def _diff_directories(\n        self, dir1: \"Directory\", dir2: \"Directory\", parent=\"\"\n    ) -&gt; Dict[str, List[str]]:\n        from .directory import Directory\n\n        diffs = {self.name1: [], self.name2: []}\n\n        keys1 = set(dir1.keys())\n        keys2 = set(dir2.keys())\n\n        # Check for keys only in dir1\n        for key in keys1 - keys2:\n            val = dir1[key]\n            if isinstance(val, H5Reader):\n                val = val[()]\n            diffs[self.name1].append(self._format_diff(\"+\", key, val, parent))\n            diffs[self.name2].append(self._format_diff(\"-\", key, val, parent))\n\n        # Check for keys only in dir2\n        for key in keys2 - keys1:\n            val = dir2[key]\n            if isinstance(val, H5Reader):\n                val = val[()]\n            diffs[self.name2].append(self._format_diff(\"+\", key, val, parent))\n            diffs[self.name1].append(self._format_diff(\"-\", key, val, parent))\n\n        # Check for keys present in both\n        for key in keys1 &amp; keys2:\n            val1 = dir1[key]\n            val2 = dir2[key]\n            if isinstance(val1, Directory) and isinstance(val2, Directory):\n                child_diffs = self._diff_directories(\n                    val1, val2, f\"{parent}.{key}\" if parent else key\n                )\n                diffs[self.name1].extend(child_diffs[self.name1])\n                diffs[self.name2].extend(child_diffs[self.name2])\n\n            elif isinstance(val1, H5Reader) and isinstance(val2, H5Reader):\n                val1 = val1[()]\n                val2 = val2[()]\n                equal = np.array_equal(val1, val2)\n                equal = equal &amp; isinstance(val1, type(val2))\n                equal = equal &amp; (val1.dtype == val2.dtype)\n                if not equal:\n                    diffs[self.name1].append(self._format_diff(\"\u2260\", key, val1, parent))\n                    diffs[self.name2].append(self._format_diff(\"\u2260\", key, val2, parent))\n\n            elif isinstance(val1, pd.DataFrame) and isinstance(val2, pd.DataFrame):\n                equal = val1.equals(val2)\n                if not equal:\n                    diffs[self.name1].append(self._format_diff(\"\u2260\", key, val1, parent))\n                    diffs[self.name2].append(self._format_diff(\"\u2260\", key, val2, parent))\n\n            elif val1 != val2:\n                diffs[self.name1].append(self._format_diff(\"\u2260\", key, val1, parent))\n                diffs[self.name2].append(self._format_diff(\"\u2260\", key, val2, parent))\n\n        return diffs\n\n    def _format_diff(self, symbol, key, value, parent):\n        full_key = f\"{parent}.{key}\" if parent else key\n        return f\"{symbol}{full_key}: {value}\"\n</code></pre>"},{"location":"reference/diff/#datamate.diff.DirectoryDiff.equal","title":"equal","text":"<pre><code>equal(fail=False)\n</code></pre> <p>Return True if the directories are equal.</p> <p>Parameters:</p> Name Type Description Default <code>fail</code> <code>bool</code> <p>If True, raise AssertionError when directories differ.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if directories are equal, False otherwise.</p> <p>Raises:</p> Type Description <code>AssertionError</code> <p>If directories differ and <code>fail=True</code>.</p> Source code in <code>datamate/diff.py</code> <pre><code>def equal(self, fail: bool = False) -&gt; bool:\n    \"\"\"Return True if the directories are equal.\n\n    Args:\n        fail: If True, raise AssertionError when directories differ.\n\n    Returns:\n        bool: True if directories are equal, False otherwise.\n\n    Raises:\n        AssertionError: If directories differ and `fail=True`.\n    \"\"\"\n    try:\n        assert_equal_directories(self.directory1, self.directory2)\n        return True\n    except AssertionError as e:\n        if fail:\n            raise AssertionError from e\n        return False\n</code></pre>"},{"location":"reference/diff/#datamate.diff.DirectoryDiff.diff","title":"diff","text":"<pre><code>diff(invert=False)\n</code></pre> <p>Return differences between the directories.</p> <p>Parameters:</p> Name Type Description Default <code>invert</code> <code>bool</code> <p>If True, swap the order of comparison.</p> <code>False</code> <p>Returns:</p> Type Description <code>Dict[str, List[str]]</code> <p>Dict[str, List[str]]: Dictionary containing differences, keyed by directory names.</p> Source code in <code>datamate/diff.py</code> <pre><code>def diff(self, invert: bool = False) -&gt; Dict[str, List[str]]:\n    \"\"\"Return differences between the directories.\n\n    Args:\n        invert: If True, swap the order of comparison.\n\n    Returns:\n        Dict[str, List[str]]: Dictionary containing differences, keyed by directory names.\n    \"\"\"\n    if invert:\n        return self._diff_directories(self.directory2, self.directory1)\n    return self._diff_directories(self.directory1, self.directory2)\n</code></pre>"},{"location":"reference/diff/#datamate.diff.DirectoryDiff.config_diff","title":"config_diff","text":"<pre><code>config_diff()\n</code></pre> <p>Return the differences between the configurations of the directories.</p> Source code in <code>datamate/diff.py</code> <pre><code>def config_diff(self) -&gt; Dict[str, List[str]]:\n    \"\"\"Return the differences between the configurations of the directories.\"\"\"\n    return self.directory1.config.diff(\n        self.directory2.config, name1=self.name1, name2=self.name2\n    )\n</code></pre>"},{"location":"reference/diff/#datamate.diff.assert_equal_attributes","title":"assert_equal_attributes","text":"<pre><code>assert_equal_attributes(directory, target)\n</code></pre> <p>Assert that two directories have equal attributes.</p> <p>Parameters:</p> Name Type Description Default <code>directory</code> <code>Directory</code> <p>First directory to compare.</p> required <code>target</code> <code>Directory</code> <p>Second directory to compare.</p> required <p>Raises:</p> Type Description <code>AssertionError</code> <p>If directories have different attributes.</p> Source code in <code>datamate/diff.py</code> <pre><code>def assert_equal_attributes(directory: \"Directory\", target: \"Directory\") -&gt; None:\n    \"\"\"Assert that two directories have equal attributes.\n\n    Args:\n        directory: First directory to compare.\n        target: Second directory to compare.\n\n    Raises:\n        AssertionError: If directories have different attributes.\n    \"\"\"\n    if directory.path == target.path:\n        return\n    assert isinstance(directory, type(target))\n    assert directory._config == target._config\n    assert directory.meta == target.meta\n    assert directory.__doc__ == target.__doc__\n    assert directory.path.exists() == target.path.exists()\n</code></pre>"},{"location":"reference/diff/#datamate.diff.assert_equal_directories","title":"assert_equal_directories","text":"<pre><code>assert_equal_directories(directory, target)\n</code></pre> <p>Assert that two directories are equal.</p> <p>Parameters:</p> Name Type Description Default <code>directory</code> <code>Directory</code> <p>First directory to compare.</p> required <code>target</code> <code>Directory</code> <p>Second directory to compare.</p> required <p>Raises:</p> Type Description <code>AssertionError</code> <p>If directories differ in structure or content.</p> Source code in <code>datamate/diff.py</code> <pre><code>def assert_equal_directories(directory: \"Directory\", target: \"Directory\") -&gt; None:\n    \"\"\"Assert that two directories are equal.\n\n    Args:\n        directory: First directory to compare.\n        target: Second directory to compare.\n\n    Raises:\n        AssertionError: If directories differ in structure or content.\n    \"\"\"\n    from .directory import Directory\n\n    assert_equal_attributes(directory, target)\n\n    assert len(directory) == len(target)\n    assert len(list(directory)) == len(list(target))\n\n    keys1 = set(directory.keys())\n    keys2 = set(target.keys())\n    assert keys1 == keys2\n\n    for k in keys1 &amp; keys2:\n        assert k in directory and k in target\n        assert k in list(directory) and k in list(target)\n        assert hasattr(directory, k) and hasattr(target, k)\n\n        v1 = directory[k]\n        v2 = target[k]\n\n        if isinstance(v1, Directory):\n            assert isinstance(v2, Directory)\n            assert isinstance(getattr(directory, k), Directory) and isinstance(\n                getattr(target, k), Directory\n            )\n            assert_equal_directories(v1, v2)\n            assert_equal_directories(getattr(directory, k), v1)\n            assert_equal_directories(getattr(target, k), v2)\n\n        elif isinstance(v1, Path):\n            assert isinstance(v2, Path)\n            assert isinstance(getattr(directory, k), Path) and isinstance(\n                getattr(target, k), Path\n            )\n            assert v1.read_bytes() == v2.read_bytes()\n            assert getattr(directory, k).read_bytes() == v1.read_bytes()\n            assert getattr(target, k).read_bytes() == v2.read_bytes()\n\n        elif isinstance(v1, pd.DataFrame):\n            assert isinstance(v2, pd.DataFrame)\n            assert isinstance(getattr(directory, k), pd.DataFrame) and isinstance(\n                getattr(target, k), pd.DataFrame\n            )\n            assert v1.equals(v2)\n            assert getattr(directory, k).equals(v1)\n            assert getattr(target, k).equals(v2)\n\n        else:\n            assert isinstance(v1, H5Reader)\n            assert isinstance(v2, H5Reader)\n            assert isinstance(getattr(directory, k), H5Reader) and isinstance(\n                getattr(target, k), H5Reader\n            )\n            assert np.array_equal(v1[()], v2[()])\n            assert np.array_equal(getattr(directory, k)[()], v1[()])\n            assert np.array_equal(getattr(target, k)[()], v2[()])\n            assert v1.dtype == v2.dtype\n            assert getattr(directory, k).dtype == v1.dtype\n            assert getattr(target, k).dtype == v2.dtype\n</code></pre>"},{"location":"reference/directory/","title":"Directory","text":""},{"location":"reference/directory/#datamate.directory","title":"datamate.directory","text":"<p>This module exports the <code>Directory</code> class, an array- and metadata-friendly view into a directory.</p> <p>Instances of the base Directory class have methods to simplify reading/writing collections of arrays.</p>"},{"location":"reference/directory/#datamate.directory.Directory","title":"Directory","text":"<p>Array- and metadata-friendly view into a directory.</p> <p>Provides a dictionary-like interface for working with arrays and metadata stored in a directory structure.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Optional[Path]</code> <p>Path at which the Directory is/should be stored. Can be relative to current <code>root_dir</code>. If not provided, the Directory is created relative to the current <code>root_dir</code>.</p> required <code>config</code> <code>Optional[Dict[str, Any]]</code> <p>Configuration dictionary. When including a <code>type</code> field, indicates the Directory type to search for and construct.</p> required <p>Attributes:</p> Name Type Description <code>path</code> <code>Path</code> <p>Path where Directory is stored. Type: <code>pathlib.Path</code></p> <code>config</code> <code>Config</code> <p>Directory configuration. Type: <code>Config</code></p> <code>meta</code> <code>Namespace</code> <p>Metadata stored in <code>_meta.yaml</code>. Type: <code>Namespace</code></p> <code>status</code> <code>Literal['running', 'done', 'stopped']</code> <p>Build status from metadata. Type: <code>Literal[\"running\", \"done\", \"stopped\"]</code></p> <code>parent</code> <code>Directory</code> <p>Parent directory. Type: <code>Directory</code></p> Valid constructors <pre><code># Auto-name relative to root_dir:\nDirectory()\nDirectory(config={\"type\": \"MyType\"})\n\n# Name relative to root_dir or absolute:\nDirectory(\"/path/to/dir\")\nDirectory(\"/path/to/dir\", config={\"type\": \"MyType\"})\n</code></pre> <p>After instantiation, Directories act as string-keyed mutable dictionaries containing: - ArrayFiles: Single-entry HDF5 files in SWMR mode - Paths: Non-array files in other formats - Directories: Subdirectories</p> <p>Array-like numeric and byte-string data written via <code>__setitem__</code>, <code>__setattr__</code>, or <code>extend</code> is stored as an array file.</p> Example <pre><code># Create directory with arrays\ndir = Directory(\"my_data\")\ndir[\"array1\"] = np.array([1,2,3])\ndir.array2 = np.array([[4,5],[6,7]])\n\n# Access data\narr1 = dir[\"array1\"]  # Returns array([1,2,3])\narr2 = dir.array2     # Returns array([[4,5],[6,7]])\n</code></pre> Source code in <code>datamate/directory.py</code> <pre><code>class Directory(metaclass=NonExistingDirectory):\n    \"\"\"Array- and metadata-friendly view into a directory.\n\n    Provides a dictionary-like interface for working with arrays and metadata stored in\n    a directory structure.\n\n    Args:\n        path (Optional[Path]): Path at which the Directory is/should be stored.\n            Can be relative to current `root_dir`. If not provided, the Directory is\n            created relative to the current `root_dir`.\n        config (Optional[Dict[str, Any]]): Configuration dictionary. When including a\n            `type` field, indicates the Directory type to search for and construct.\n\n    Attributes:\n        path: Path where Directory is stored.\n            Type: `pathlib.Path`\n        config: Directory configuration.\n            Type: `Config`\n        meta: Metadata stored in `_meta.yaml`.\n            Type: `Namespace`\n        status: Build status from metadata.\n            Type: `Literal[\"running\", \"done\", \"stopped\"]`\n        parent: Parent directory.\n            Type: `Directory`\n\n    Valid constructors:\n        ```python\n        # Auto-name relative to root_dir:\n        Directory()\n        Directory(config={\"type\": \"MyType\"})\n\n        # Name relative to root_dir or absolute:\n        Directory(\"/path/to/dir\")\n        Directory(\"/path/to/dir\", config={\"type\": \"MyType\"})\n        ```\n\n    After instantiation, Directories act as string-keyed mutable dictionaries\n    containing:\n    - ArrayFiles: Single-entry HDF5 files in SWMR mode\n    - Paths: Non-array files in other formats\n    - Directories: Subdirectories\n\n    Array-like numeric and byte-string data written via `__setitem__`, `__setattr__`, or\n    `extend` is stored as an array file.\n\n    Example:\n        ```python\n        # Create directory with arrays\n        dir = Directory(\"my_data\")\n        dir[\"array1\"] = np.array([1,2,3])\n        dir.array2 = np.array([[4,5],[6,7]])\n\n        # Access data\n        arr1 = dir[\"array1\"]  # Returns array([1,2,3])\n        arr2 = dir.array2     # Returns array([[4,5],[6,7]])\n        ```\n    \"\"\"\n\n    class Config(Protocol):\n        \"\"\"Protocol defining the configuration interface for Directory classes.\n\n        This protocol defines the structure of the `config` argument to the\n        `Directory` constructor, and provides type hints for the `config`\n        attribute of `Directory` instances.\n\n        Note:\n            Subclasses should implement this protocol to define their configuration\n            interface, or implement `__init__` with typed parameters.\n        \"\"\"\n\n        pass\n\n    path: Path\n    config: Config\n\n    @overload\n    def __new__(cls: type[T]) -&gt; T: ...\n\n    @overload\n    def __new__(cls: type[T], path: Union[str, Path]) -&gt; T: ...\n\n    @overload\n    def __new__(cls: type[T], config: ConfigType) -&gt; T: ...\n\n    @overload\n    def __new__(cls: type[T], path: Union[str, Path], config: ConfigType) -&gt; T: ...\n\n    def __new__(_type: type[T], *args: object, **kwargs: object) -&gt; T:\n        \"\"\"Implementation of overloaded constructors.\"\"\"\n        path, config = _parse_directory_args(args, kwargs)\n\n        if path is not None and isinstance(path, Path) and path.exists():\n            # case 1: path exists and global context is deleting if exists\n            if context.delete_if_exists:\n                shutil.rmtree(path)\n            # case 2: path exists and local kwargs are deleting if exists\n            if (\n                config is not None\n                and \"delete_if_exists\" in config\n                and config[\"delete_if_exists\"]\n            ):\n                shutil.rmtree(path)\n\n            if config is not None and \"delete_if_exists\" in config:\n                # always remove the deletion flag from the config\n                config.pop(\"delete_if_exists\")\n\n        cls = _directory(_type)\n        _check_implementation(cls)\n\n        defaults = get_defaults(cls)\n\n        if config is None and defaults:  # and _implements_init(cls):\n            # to initialize from defaults if no config or path is provided\n            if path is None or path is not None and not path.exists():\n                config = defaults\n            # if a non-empty path is provided, we cannot initialize from defaults\n            else:\n                pass\n        # breakpoint()\n        if path is not None and config is None:\n            cls = _directory_from_path(cls, _resolve_path(path))\n        elif path is None and config is not None:\n            cls = _directory_from_config(cls, config)\n        elif path is not None and config is not None:\n            cls = _directory_from_path_and_config(cls, _resolve_path(path), config)\n        elif path is None and config is None and _implements_init(cls):\n            # raise ValueError(\"no configuration provided\")\n            pass\n\n        if context.check_size_on_init:\n            cls.check_size()\n\n        return cls\n\n    def __init__(self) -&gt; None:\n        \"\"\"Implement to compile `Directory` from a configuration.\n\n        Note:\n            Subclasses can either implement `Config` to determine the interface,\n            types and defaults of `config`, or implement `__init__` with keyword\n            arguments. If both are implemented, the config is created from the joined\n            interface as long as defaults are not conflicting.\n        \"\"\"\n        pass\n\n    def __init_subclass__(cls, **kwargs) -&gt; None:\n        \"\"\"Initializes a Directory subclass.\n\n        Automatically generates documentation for the subclass.\n\n        Args:\n            **kwargs: Additional keyword arguments passed to parent __init_subclass__\n        \"\"\"\n        super().__init_subclass__(**kwargs)\n        cls.__doc__ = _auto_doc(cls)\n\n    @property\n    def meta(self) -&gt; Namespace:\n        \"\"\"The metadata stored in `{self.path}/_meta.yaml`.\"\"\"\n        return read_meta(self.path)\n\n    @property\n    def config(self) -&gt; Config:\n        \"\"\"The directory configuration.\"\"\"\n        return self.meta.config or self._config\n\n    @config.setter\n    def config(self, value: Config) -&gt; None:\n        self.__manual_config(value)\n\n    @property\n    def status(self) -&gt; Literal[\"running\", \"done\", \"stopped\"]:\n        \"\"\"The build status from metadata.\"\"\"\n        return self.meta.status\n\n    @property\n    def size(self) -&gt; int:\n        \"\"\"Total size of directory in bytes.\"\"\"\n        return check_size(self.path, warning_at=float(\"inf\"), print_size=False)\n\n    @property\n    def is_empty(self) -&gt; bool:\n        \"\"\"Whether directory contains any files.\"\"\"\n        return len(self) == 0\n\n    @property\n    def modified(self) -&gt; bool:\n        \"\"\"Whether directory has been modified after initialization.\"\"\"\n        return getattr(self.meta, \"modified\", False)\n\n    # -- MutableMapping methods ----------------------------\n\n    def __len__(self) -&gt; int:\n        \"\"\"Returns the number of public files in `self.path`.\n\n        Non-public files (files whose names start with \"_\") are not counted.\n\n        Returns:\n            Number of public files in the directory\n        \"\"\"\n        return sum(1 for _ in self.path.glob(\"[!_]*\"))\n\n    def __iter__(self) -&gt; Iterator[str]:\n        \"\"\"Yields field names corresponding to the public files in `self.path`.\n\n        Entries it understands (subdirectories and HDF5 files) are yielded\n        without extensions. Non-public files (files whose names start with \"_\")\n        are ignored.\n\n        Yields:\n            Field names for each public file\n        \"\"\"\n        for p in self.path.glob(\"[!_]*\"):\n            yield p.name.rpartition(\".\")[0] if p.suffix in [\".h5\", \".csv\"] else p.name\n\n    def __copy__(self) -&gt; \"Directory\":\n        \"\"\"Creates a shallow copy of the directory.\n\n        Returns:\n            New `Directory` instance pointing to the same path\n        \"\"\"\n        return Directory(self.path)\n\n    def __deepcopy__(self, memodict={}):\n        return self.__copy__()\n\n    def keys(self) -&gt; Iterator[str]:\n        \"\"\"Returns an iterator over public file names in the directory.\n\n        Returns:\n            Iterator yielding public file names\n        \"\"\"\n        return self.__iter__()\n\n    def items(self) -&gt; Iterator[Tuple[str, ArrayFile]]:\n        \"\"\"Returns an iterator over (key, value) pairs in the directory.\n\n        Returns:\n            Iterator yielding tuples of (filename, file content)\n        \"\"\"\n        for key in self.keys():\n            yield (key, self[key])\n\n    @classmethod\n    def from_df(\n        cls: type[T], df: DataFrame, dtypes: Dict[str, Any], *args, **kwargs\n    ) -&gt; T:\n        \"\"\"Create a Directory from a DataFrame by splitting into column arrays.\n\n        Each column is stored as a separate HDF5 array with specified dtype.\n        This is different from storing the DataFrame directly, which uses CSV format.\n\n        Args:\n            df: Source DataFrame\n            dtypes: Dictionary mapping column names to numpy dtypes\n            *args: Additional arguments passed to `Directory` constructor\n            **kwargs: Additional keyword arguments passed to `Directory` constructor\n\n        Returns:\n            `Directory` with each column stored as a separate array\n\n        Examples:\n            ```python\n            df = pd.DataFrame({'a': [1, 2, 3], 'b': ['x', 'y', 'z']})\n            dtypes = {'a': np.int64, 'b': 'S'}\n\n            # Store columns as separate arrays\n            dir1 = Directory.from_df(df, dtypes)\n            # Results in:\n            # dir1/\n            #   \u251c\u2500\u2500 a.h5  # array([1, 2, 3])\n            #   \u2514\u2500\u2500 b.h5  # array([b'x', b'y', b'z'])\n\n            # Store as single CSV\n            dir2 = Directory()\n            dir2['data'] = df\n            # Results in:\n            # dir2/\n            #   \u2514\u2500\u2500 data.csv\n            ```\n        \"\"\"\n        directory = Directory.__new__(Directory, *args, **kwargs)\n        directory.update({\n            column: df[column].values.astype(dtypes[column]) for column in df.columns\n        })\n        return directory\n\n    def update(self, other: Union[Dict, \"Directory\"], suffix: str = \"\") -&gt; None:\n        \"\"\"Updates self with items of other and appends an optional suffix.\n\n        Args:\n            other: Dictionary or Directory to copy items from\n            suffix: Optional string to append to copied keys\n        \"\"\"\n        for key in other:\n            if key + suffix not in self:\n                self[key + suffix] = other[key]\n\n    def move(self, dst: Union[str, Path]) -&gt; \"Directory\":\n        \"\"\"Moves directory to new location.\n\n        Args:\n            dst: Destination path\n\n        Returns:\n            New `Directory` instance at the destination path\n        \"\"\"\n        shutil.move(self.path, dst)\n        return Directory(dst)\n\n    def rmtree(self, y_n: Optional[str] = None) -&gt; None:\n        \"\"\"Recursively deletes the directory after confirmation.\n\n        Args:\n            y_n: Optional pre-supplied confirmation ('y' or 'n'). If not provided,\n                will prompt user interactively\n        \"\"\"\n        reply = y_n or input(f\"delete {self.path} recursively, y/n?\")\n        if reply.lower() == \"y\":\n            shutil.rmtree(self.path, ignore_errors=True)\n\n    def _rebuild(self, y_n: Optional[str] = None) -&gt; None:\n        \"\"\"Rebuilds the directory by deleting and recreating it.\n\n        Args:\n            y_n: Optional pre-supplied confirmation ('y' or 'n'). If not provided,\n                will prompt user interactively\n        \"\"\"\n        self.rmtree(y_n)\n        _build(self)\n\n    def __truediv__(self, other: str) -&gt; Any:\n        \"\"\"Implements path-like division operator for accessing entries.\n\n        Args:\n            other: Key to access\n\n        Returns:\n            Same as `self[other]`\n        \"\"\"\n        return self.__getitem__(other)\n\n    def __getitem__(self, key: str) -&gt; Any:\n        \"\"\"Returns `ArrayFile`, `Path`, or `Directory` corresponding to `self.path/key`.\n\n        HDF5 files are returned as `ArrayFile`s, other files as `Path`s, and\n        directories and nonexistent entries as (possibly empty) `Directory`s.\n\n        Args:\n            key: Name of the entry to retrieve\n\n        Returns:\n            The requested entry as an appropriate type\n\n        Note:\n            Attribute access syntax is also supported, and occurrences of `__` in\n            `key` are transformed into `.`, to support accessing encoded files as\n            attributes (i.e. `Directory['name.ext']` is equivalent to\n            `Directory.name__ext`).\n        \"\"\"\n        # if context.in_memory:\n        #     return object.__getattribute__(self, key)\n\n        try:\n            # to catch cases where key is an index to a reference to an h5 file.\n            # this will yield a TypeError because Path / slice does not work.\n            path = self.path / key\n        except TypeError as e:\n            if not self.path.exists():\n                # we wanted to index an H5Dataset but we tried to index a Directory\n                # because the H5Dataset does not exist\n                raise FileNotFoundError(\n                    f\"Indexing {self.path.name} at {key} not possible for\"\n                    f\" Directory at {self.path.parent}. File \"\n                    f\"{self.path.name}.h5 does not exist.\"\n                ) from e\n            raise e\n\n        # Return an array.\n        if path.with_suffix(\".h5\").is_file():\n            return _read_h5(path.with_suffix(\".h5\"))\n\n        # Return a csv\n        if path.with_suffix(\".csv\").is_file():\n            return pd.read_csv(path.with_suffix(\".csv\"))\n\n        # Return the path to a file.\n        elif path.is_file():\n            return path\n\n        # Return a subrecord\n        else:\n            return Directory(path)\n\n    def __setitem__(self, key: str, val: object) -&gt; None:\n        \"\"\"\n        Writes an `ArrayFile`, `Path`, or `Directory` to `self.path/key`\n\n        `np.ndarray`-like objects are written as `ArrayFiles`, `Path`-like\n        objects are written as `Path`s, and string-keyed mappings are\n        written as subDirectorys.\n\n        Attribute access syntax is also supported, and occurrences of \"__\" in\n        `key` are transformed into \".\", to support accessing encoded files as\n        attributes (i.e. `Directory['name.ext'] = val` is equivalent to\n        `Directory.name__ext = val`).\n        \"\"\"\n        # if context.in_memory:\n        #     object.__setattr__(self, key, val)\n        #     return\n\n        path = self.path / key\n\n        # Copy an existing file or directory.\n        if isinstance(val, Path):\n            if os.path.isfile(val):\n                _copy_file(path, val)\n            elif os.path.isdir(val):\n                _copy_dir(path, val)\n\n        # Write a Directory instance\n        elif isinstance(val, Directory):\n            assert path.suffix == \"\"\n            # Create new directory with same type and config as source\n            new_dir = type(val)(path, config=val.config)\n            MutableMapping.update(new_dir, val)\n\n        # Write a mapping as a new Directory\n        elif isinstance(val, Mapping):\n            assert path.suffix == \"\"\n            MutableMapping.update(Directory(path), val)  # type: ignore\n\n        # Write a dataframe.\n        elif isinstance(val, pd.DataFrame):  # Use pd.DataFrame explicitly\n            assert path.suffix == \"\"\n            if not path.parent.exists():\n                path.parent.mkdir(parents=True, exist_ok=True)\n            val.to_csv(path.with_suffix(\".csv\"), index=False)\n\n        # Write an array.\n        else:\n            assert path.suffix == \"\"\n            if isinstance(val, H5Reader):\n                val = val[()]\n            try:\n                _write_h5(path.with_suffix(\".h5\"), val)\n            except TypeError as err:\n                raise TypeError(\n                    format_tb(err.__traceback__)[0]\n                    + err.args[0]\n                    + f\"\\nYou're trying to store {val} which cannot be converted to \"\n                    f\"h5-file in {path}.\"\n                    + \"\\nFor reference of supported types, see \"\n                    + \"https://docs.h5py.org/en/stable/faq.html?highlight=types\"\n                    + \"#numpy-object-types\"\n                    + \"\\nE.g. NumPy unicode strings must be converted to 'S' strings \"\n                    + \"and back:\"\n                    + \"\\nfoo.bar = array.astype('S') to store and foo.bar[:].\"\n                    + \"astype('U') \"\n                    + \"to retrieve.\"\n                ) from None\n\n        if self.config is not None and self.status == \"done\":\n            # Track if a Directory has been modified past __init__\n            self._modified_past_init(True)\n\n    def __delitem__(self, key: str) -&gt; None:\n        \"\"\"\n        Deletes the entry at `self.path/key`\n\n        Attribute access syntax is also supported, and occurrences of \"__\" in\n        `key` are transformed into \".\", to support accessing encoded files as\n        attributes (i.e. `del Directory['name.ext']` is equivalent to\n        `del Directory.name__ext`).\n        \"\"\"\n        # if context.in_memory:\n        #     object.__delitem__(self, key)\n        #     return\n        path = self.path / key\n\n        # Delete an array file.\n        if path.with_suffix(\".h5\").is_file():\n            path.with_suffix(\".h5\").unlink()\n\n        # Delete a csv file.\n        if path.with_suffix(\".csv\").is_file():\n            path.with_suffix(\".csv\").unlink()\n\n        # Delete a non-array file.\n        elif path.is_file():\n            path.unlink()\n\n        # Delete a Directory.\n        else:\n            shutil.rmtree(path, ignore_errors=True)\n\n    def __eq__(self, other: object) -&gt; bool:\n        \"\"\"Returns True if `self` and `other` are equal.\n\n        Two Directories are equal if they have the same keys and the same\n        values for each key.\n\n        Args:\n            other: Object to compare against\n\n        Returns:\n            Whether the directories are equal\n\n        Raises:\n            ValueError: If comparing `Directory` with incompatible type\n        \"\"\"\n        if not isinstance(other, Directory):\n            raise ValueError(f\"Cannot compare Directory to {type(other)}\")\n\n        if self.path == other.path:\n            return True\n\n        if self.path != other.path:\n            diff = DirectoryDiff(self, other)\n            return diff.equal(fail=False)\n\n    def __neq__(self, other: object) -&gt; bool:\n        \"\"\"Returns True if directories are not equal.\n\n        Args:\n            other: Object to compare against\n\n        Returns:\n            Whether the directories are not equal\n        \"\"\"\n        return not self.__eq__(other)\n\n    def diff(self, other: \"Directory\") -&gt; Dict[str, List[str]]:\n        \"\"\"Returns a dictionary of differences between this directory and another.\n\n        Args:\n            other: Directory to compare against\n\n        Returns:\n            Dictionary with two keys - the name of self and other. Values are lists of\n            strings describing differences between corresponding entries.\n        \"\"\"\n        diff = DirectoryDiff(self, other)\n        return diff.diff()\n\n    def extend(self, key: str, val: object) -&gt; None:\n        \"\"\"Extends an array, file or directory at the given key.\n\n        Extending arrays performs concatenation along the first axis,\n        extending files performs byte-level concatenation, and\n        extending directories extends their fields.\n\n        Args:\n            key: Name of the entry to extend\n            val: Value to append to the existing entry. Can be `np.ndarray`, `Path`,\n                `Directory`, or `Mapping`\n\n        Note:\n            Files corresponding to `self[key]` are created if they do not already exist.\n        \"\"\"\n        # if context.in_memory:\n        #     self.__setitem__(key, np.append(self.__getitem__(key), val, axis=0))\n\n        path = self.path / key\n\n        # Append an existing file.\n        if isinstance(val, Path):\n            assert path.suffix != \"\"\n            _extend_file(path, val)\n\n        # Append a subDirectory.\n        elif isinstance(val, (Mapping, Directory)):\n            assert path.suffix == \"\"\n            for k in val:\n                Directory(path).extend(k, val[k])\n\n        elif isinstance(val, pd.DataFrame):\n            assert path.suffix == \"\"\n            if path.with_suffix(\".csv\").is_file():\n                old_df = pd.read_csv(path.with_suffix(\".csv\"))\n                new_df = pd.concat([old_df, val], axis=0)\n            else:\n                new_df = val\n            new_df.to_csv(path.with_suffix(\".csv\"), index=False)\n\n        # Append an array.\n        else:\n            assert path.suffix == \"\"\n            if isinstance(val, H5Reader):\n                val = val[()]\n            _extend_h5(path.with_suffix(\".h5\"), val)\n\n        if self.config is not None and self.status == \"done\":\n            # Track if a Directory has been modified past __init__\n            self._modified_past_init(True)\n\n    # --- Views ---\n\n    def __repr__(self):\n        if context.verbosity_level == 1:\n            string = tree(\n                self.path,\n                last_modified=True,\n                level=2,\n                length_limit=25,\n                verbose=True,\n                not_exists_message=\"empty\",\n            )\n        elif context.verbosity_level == 0:\n            string = tree(\n                self.path,\n                last_modified=True,\n                level=1,\n                length_limit=0,\n                verbose=False,\n                not_exists_message=\"empty\",\n            )\n        else:\n            string = tree(\n                self.path,\n                level=-1,\n                length_limit=None,\n                last_modified=True,\n                verbose=True,\n                limit_to_directories=False,\n            )\n        return string\n\n    def tree(\n        self,\n        level: int = -1,\n        length_limit: Optional[int] = None,\n        verbose: bool = True,\n        last_modified: bool = True,\n        limit_to_directories: bool = False,\n    ) -&gt; None:\n        \"\"\"Prints a tree representation of the directory structure.\n\n        Args:\n            level: Maximum depth to display (-1 for unlimited)\n            length_limit: Maximum number of entries to show per directory\n            verbose: Whether to show detailed information\n            last_modified: Whether to show last modification times\n            limit_to_directories: Whether to only show directories\n        \"\"\"\n        print(\n            tree(\n                self.path,\n                level=level,\n                length_limit=length_limit,\n                last_modified=last_modified,\n                verbose=verbose,\n                limit_to_directories=limit_to_directories,\n            )\n        )\n\n    # -- Attribute-style element access --------------------\n\n    def __getattr__(self, key: str) -&gt; Any:\n        if key.startswith(\"__\") and key.endswith(\"__\"):  # exclude dunder attributes\n            return None\n        return self.__getitem__(key.replace(\"__\", \".\"))\n\n    def __setattr__(self, key: str, value: object) -&gt; None:\n        # Fix autoreload related effect.\n        if key.startswith(\"__\") and key.endswith(\"__\"):\n            object.__setattr__(self, key, value)\n            return\n        # allow manual config writing\n        if key == \"config\":\n            self.__manual_config(value)\n            return\n        self.__setitem__(key.replace(\"__\", \".\"), value)\n\n    def __delattr__(self, key: str) -&gt; None:\n        self.__delitem__(key.replace(\"__\", \".\"))\n\n    # -- Attribute preemption, for REPL autocompletion -----\n\n    def __getattribute__(self, key: str) -&gt; Any:\n        if key in object.__getattribute__(self, \"_cached_keys\"):\n            try:\n                object.__setattr__(self, key, self[key])\n            except KeyError:\n                object.__delattr__(self, key)\n                object.__getattribute__(self, \"_cached_keys\").remove(key)\n        return object.__getattribute__(self, key)\n\n    def __dir__(self) -&gt; List[str]:\n        for key in self._cached_keys:\n            object.__delattr__(self, key)\n        self._cached_keys.clear()\n\n        for key in set(self).difference(object.__dir__(self)):\n            object.__setattr__(self, key, self[key])\n            self._cached_keys.add(key)\n\n        return cast(list, object.__dir__(self))\n\n    # -- Convenience methods\n\n    def __manual_config(self, config, status=None):\n        \"\"\"Overriding config stored in _meta.yaml.\n\n        config (Dict): update for meta.config\n        status (str): status if config did not exist before, i.e. _overrid_config\n            is used to store a _meta.yaml for the first time instead of build.\n        \"\"\"\n        meta_path = self.path / \"_meta.yaml\"\n\n        current_config = self.config\n        config = namespacify(config)\n        if current_config is not None:\n            with warnings.catch_warnings():\n                warnings.simplefilter(\"always\")\n                warnings.warn(\n                    (\n                        f\"Overriding config. Diff is:\"\n                        f'{config.diff(current_config, name1=\"passed\", name2=\"stored\")}'\n                    ),\n                    ConfigWarning,\n                    stacklevel=2,\n                )\n            write_meta(path=meta_path, config=config, status=\"manually written\")\n        else:\n            write_meta(path=meta_path, config=config, status=status or self.status)\n\n    def _override_status(self, status: Literal[\"running\", \"done\", \"stopped\"]) -&gt; None:\n        \"\"\"Overrides the build status in metadata.\n\n        Args:\n            status: New status to set. Must be one of \"running\", \"done\", or \"stopped\"\n\n        Warns:\n            `ConfigWarning`: When overriding an existing status\n        \"\"\"\n        meta_path = self.path / \"_meta.yaml\"\n\n        current_status = self.status\n        if current_status is not None:\n            with warnings.catch_warnings():\n                warnings.simplefilter(\"always\")\n                warnings.warn(\n                    (f\"Overriding status {current_status} to {status}\"),\n                    ConfigWarning,\n                    stacklevel=2,\n                )\n        write_meta(path=meta_path, config=self.config, status=status)\n\n    def _modified_past_init(self, is_modified: bool) -&gt; None:\n        \"\"\"Tracks if a `Directory` has been modified after initialization.\n\n        Updates the metadata file to record modification status.\n\n        Args:\n            is_modified: Whether the directory has been modified\n\n        Note:\n            This is used to warn users when attempting to reuse a modified directory.\n        \"\"\"\n        meta_path = self.path / \"_meta.yaml\"\n\n        if is_modified:\n            write_meta(\n                path=meta_path, config=self.config, status=self.status, modified=True\n            )\n\n    def check_size(\n        self,\n        warning_at: int = 20 * 1024**3,  # 20GB\n        print_size: bool = False,\n        *,\n        raise_on_warning: bool = False,\n    ) -&gt; int:\n        \"\"\"Checks the total size of the directory.\n\n        Args:\n            warning_at: Size in bytes at which to issue a warning\n            print_size: Whether to print the directory size\n            raise_on_warning: Whether to raise exception instead of warning\n\n        Returns:\n            Total size in bytes\n\n        Raises:\n            ValueError: if directory size exceeds warning_at and raise_on_warning\n                is True\n        \"\"\"\n        size = check_size(self.path, warning_at, print_size)\n        if raise_on_warning and size &gt; warning_at:\n            raise ValueError(f\"Directory size {size} exceeds limit {warning_at}\")\n        return size\n\n    def to_df(self, dtypes: Optional[Dict[str, Any]] = None) -&gt; DataFrame:\n        \"\"\"Reconstruct a DataFrame from HDF5 column arrays in this directory.\n\n        Combines all equal-length, single-dimensional HDF5 datasets into\n        DataFrame columns. Results are cached to avoid expensive recomputation.\n\n        Args:\n            dtypes: Optional dictionary mapping column names to numpy dtypes\n\n        Returns:\n            `DataFrame` reconstructed from HDF5 column arrays\n\n        Note:\n            This is the complement to `from_df()`. While direct DataFrame assignment\n            stores as CSV, `from_df()` splits columns into HDF5 arrays which can be\n            recombined using this method.\n        \"\"\"\n        try:\n            return object.__getattribute__(self, \"_as_df\")\n        except AttributeError:\n            object.__setattr__(self, \"_as_df\", directory_to_df(self, dtypes))\n            return self.to_df()\n\n    def to_dict(self) -&gt; DataFrame:\n        \"\"\"\n        Returns a DataFrame from all equal length, single-dim .h5 datasets in self.path.\n        \"\"\"\n        # to cache the dict that is expensive to create.\n        try:\n            return object.__getattribute__(self, \"_as_dict\")\n        except AttributeError:\n            object.__setattr__(self, \"_as_dict\", directory_to_dict(self))\n            return self.to_dict()\n\n    def mtime(self) -&gt; datetime.datetime:\n        \"\"\"Returns the last modification time of the directory.\n\n        Returns:\n            Datetime object representing last modification time\n        \"\"\"\n        return datetime.datetime.fromtimestamp(self.path.stat().st_mtime)\n\n    @property\n    def parent(self) -&gt; \"Directory\":\n        \"\"\"The parent directory.\"\"\"\n        return Directory(self.path.absolute().parent)\n\n    def _count(self) -&gt; int:\n        \"\"\"Counts number of existing numbered subdirectories.\n\n        Returns:\n            Number of subdirectories matching pattern '[0-9a-f]{4}'\n        \"\"\"\n        root = self.path\n        count = 0\n        for i in itertools.count():\n            dst = root / f\"{i:04x}\"\n            if dst.exists():\n                count += 1\n            else:\n                return count\n        return count\n\n    def _next(self) -&gt; \"Directory\":\n        \"\"\"Creates next available numbered subdirectory.\n\n        Returns:\n            New `Directory` instance for the next available numbered subdirectory\n\n        Raises:\n            AssertionError: If the next numbered directory already exists\n        \"\"\"\n        root = self.path\n        dst = root / f\"{self._count():04x}\"\n        assert not dst.exists()\n        return Directory(dst, self.config)\n\n    def _clear_filetype(self, suffix: str) -&gt; None:\n        \"\"\"Deletes all files with given suffix in the current directory.\n\n        Args:\n            suffix: File extension to match (e.g. '.h5', '.csv')\n        \"\"\"\n        for file in self.path.iterdir():\n            if file.is_file() and file.suffix == suffix:\n                file.unlink()\n</code></pre>"},{"location":"reference/directory/#datamate.directory.Directory.meta","title":"meta  <code>property</code>","text":"<pre><code>meta\n</code></pre> <p>The metadata stored in <code>{self.path}/_meta.yaml</code>.</p>"},{"location":"reference/directory/#datamate.directory.Directory.config","title":"config  <code>property</code> <code>writable</code>","text":"<pre><code>config\n</code></pre> <p>The directory configuration.</p>"},{"location":"reference/directory/#datamate.directory.Directory.status","title":"status  <code>property</code>","text":"<pre><code>status\n</code></pre> <p>The build status from metadata.</p>"},{"location":"reference/directory/#datamate.directory.Directory.size","title":"size  <code>property</code>","text":"<pre><code>size\n</code></pre> <p>Total size of directory in bytes.</p>"},{"location":"reference/directory/#datamate.directory.Directory.is_empty","title":"is_empty  <code>property</code>","text":"<pre><code>is_empty\n</code></pre> <p>Whether directory contains any files.</p>"},{"location":"reference/directory/#datamate.directory.Directory.modified","title":"modified  <code>property</code>","text":"<pre><code>modified\n</code></pre> <p>Whether directory has been modified after initialization.</p>"},{"location":"reference/directory/#datamate.directory.Directory.parent","title":"parent  <code>property</code>","text":"<pre><code>parent\n</code></pre> <p>The parent directory.</p>"},{"location":"reference/directory/#datamate.directory.Directory.Config","title":"Config","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol defining the configuration interface for Directory classes.</p> <p>This protocol defines the structure of the <code>config</code> argument to the <code>Directory</code> constructor, and provides type hints for the <code>config</code> attribute of <code>Directory</code> instances.</p> Note <p>Subclasses should implement this protocol to define their configuration interface, or implement <code>__init__</code> with typed parameters.</p> Source code in <code>datamate/directory.py</code> <pre><code>class Config(Protocol):\n    \"\"\"Protocol defining the configuration interface for Directory classes.\n\n    This protocol defines the structure of the `config` argument to the\n    `Directory` constructor, and provides type hints for the `config`\n    attribute of `Directory` instances.\n\n    Note:\n        Subclasses should implement this protocol to define their configuration\n        interface, or implement `__init__` with typed parameters.\n    \"\"\"\n\n    pass\n</code></pre>"},{"location":"reference/directory/#datamate.directory.Directory.__new__","title":"__new__","text":"<pre><code>__new__() -&gt; T\n</code></pre><pre><code>__new__(path: Union[str, Path]) -&gt; T\n</code></pre><pre><code>__new__(config: ConfigType) -&gt; T\n</code></pre><pre><code>__new__(path: Union[str, Path], config: ConfigType) -&gt; T\n</code></pre> <pre><code>__new__(_type, *args, **kwargs)\n</code></pre> <p>Implementation of overloaded constructors.</p> Source code in <code>datamate/directory.py</code> <pre><code>def __new__(_type: type[T], *args: object, **kwargs: object) -&gt; T:\n    \"\"\"Implementation of overloaded constructors.\"\"\"\n    path, config = _parse_directory_args(args, kwargs)\n\n    if path is not None and isinstance(path, Path) and path.exists():\n        # case 1: path exists and global context is deleting if exists\n        if context.delete_if_exists:\n            shutil.rmtree(path)\n        # case 2: path exists and local kwargs are deleting if exists\n        if (\n            config is not None\n            and \"delete_if_exists\" in config\n            and config[\"delete_if_exists\"]\n        ):\n            shutil.rmtree(path)\n\n        if config is not None and \"delete_if_exists\" in config:\n            # always remove the deletion flag from the config\n            config.pop(\"delete_if_exists\")\n\n    cls = _directory(_type)\n    _check_implementation(cls)\n\n    defaults = get_defaults(cls)\n\n    if config is None and defaults:  # and _implements_init(cls):\n        # to initialize from defaults if no config or path is provided\n        if path is None or path is not None and not path.exists():\n            config = defaults\n        # if a non-empty path is provided, we cannot initialize from defaults\n        else:\n            pass\n    # breakpoint()\n    if path is not None and config is None:\n        cls = _directory_from_path(cls, _resolve_path(path))\n    elif path is None and config is not None:\n        cls = _directory_from_config(cls, config)\n    elif path is not None and config is not None:\n        cls = _directory_from_path_and_config(cls, _resolve_path(path), config)\n    elif path is None and config is None and _implements_init(cls):\n        # raise ValueError(\"no configuration provided\")\n        pass\n\n    if context.check_size_on_init:\n        cls.check_size()\n\n    return cls\n</code></pre>"},{"location":"reference/directory/#datamate.directory.Directory.__init__","title":"__init__","text":"<pre><code>__init__()\n</code></pre> <p>Implement to compile <code>Directory</code> from a configuration.</p> Note <p>Subclasses can either implement <code>Config</code> to determine the interface, types and defaults of <code>config</code>, or implement <code>__init__</code> with keyword arguments. If both are implemented, the config is created from the joined interface as long as defaults are not conflicting.</p> Source code in <code>datamate/directory.py</code> <pre><code>def __init__(self) -&gt; None:\n    \"\"\"Implement to compile `Directory` from a configuration.\n\n    Note:\n        Subclasses can either implement `Config` to determine the interface,\n        types and defaults of `config`, or implement `__init__` with keyword\n        arguments. If both are implemented, the config is created from the joined\n        interface as long as defaults are not conflicting.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/directory/#datamate.directory.Directory.__init_subclass__","title":"__init_subclass__","text":"<pre><code>__init_subclass__(**kwargs)\n</code></pre> <p>Initializes a Directory subclass.</p> <p>Automatically generates documentation for the subclass.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Additional keyword arguments passed to parent init_subclass</p> <code>{}</code> Source code in <code>datamate/directory.py</code> <pre><code>def __init_subclass__(cls, **kwargs) -&gt; None:\n    \"\"\"Initializes a Directory subclass.\n\n    Automatically generates documentation for the subclass.\n\n    Args:\n        **kwargs: Additional keyword arguments passed to parent __init_subclass__\n    \"\"\"\n    super().__init_subclass__(**kwargs)\n    cls.__doc__ = _auto_doc(cls)\n</code></pre>"},{"location":"reference/directory/#datamate.directory.Directory.__len__","title":"__len__","text":"<pre><code>__len__()\n</code></pre> <p>Returns the number of public files in <code>self.path</code>.</p> <p>Non-public files (files whose names start with \u201c_\u201d) are not counted.</p> <p>Returns:</p> Type Description <code>int</code> <p>Number of public files in the directory</p> Source code in <code>datamate/directory.py</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"Returns the number of public files in `self.path`.\n\n    Non-public files (files whose names start with \"_\") are not counted.\n\n    Returns:\n        Number of public files in the directory\n    \"\"\"\n    return sum(1 for _ in self.path.glob(\"[!_]*\"))\n</code></pre>"},{"location":"reference/directory/#datamate.directory.Directory.__iter__","title":"__iter__","text":"<pre><code>__iter__()\n</code></pre> <p>Yields field names corresponding to the public files in <code>self.path</code>.</p> <p>Entries it understands (subdirectories and HDF5 files) are yielded without extensions. Non-public files (files whose names start with \u201c_\u201d) are ignored.</p> <p>Yields:</p> Type Description <code>str</code> <p>Field names for each public file</p> Source code in <code>datamate/directory.py</code> <pre><code>def __iter__(self) -&gt; Iterator[str]:\n    \"\"\"Yields field names corresponding to the public files in `self.path`.\n\n    Entries it understands (subdirectories and HDF5 files) are yielded\n    without extensions. Non-public files (files whose names start with \"_\")\n    are ignored.\n\n    Yields:\n        Field names for each public file\n    \"\"\"\n    for p in self.path.glob(\"[!_]*\"):\n        yield p.name.rpartition(\".\")[0] if p.suffix in [\".h5\", \".csv\"] else p.name\n</code></pre>"},{"location":"reference/directory/#datamate.directory.Directory.__copy__","title":"__copy__","text":"<pre><code>__copy__()\n</code></pre> <p>Creates a shallow copy of the directory.</p> <p>Returns:</p> Type Description <code>Directory</code> <p>New <code>Directory</code> instance pointing to the same path</p> Source code in <code>datamate/directory.py</code> <pre><code>def __copy__(self) -&gt; \"Directory\":\n    \"\"\"Creates a shallow copy of the directory.\n\n    Returns:\n        New `Directory` instance pointing to the same path\n    \"\"\"\n    return Directory(self.path)\n</code></pre>"},{"location":"reference/directory/#datamate.directory.Directory.keys","title":"keys","text":"<pre><code>keys()\n</code></pre> <p>Returns an iterator over public file names in the directory.</p> <p>Returns:</p> Type Description <code>Iterator[str]</code> <p>Iterator yielding public file names</p> Source code in <code>datamate/directory.py</code> <pre><code>def keys(self) -&gt; Iterator[str]:\n    \"\"\"Returns an iterator over public file names in the directory.\n\n    Returns:\n        Iterator yielding public file names\n    \"\"\"\n    return self.__iter__()\n</code></pre>"},{"location":"reference/directory/#datamate.directory.Directory.items","title":"items","text":"<pre><code>items()\n</code></pre> <p>Returns an iterator over (key, value) pairs in the directory.</p> <p>Returns:</p> Type Description <code>Iterator[Tuple[str, ArrayFile]]</code> <p>Iterator yielding tuples of (filename, file content)</p> Source code in <code>datamate/directory.py</code> <pre><code>def items(self) -&gt; Iterator[Tuple[str, ArrayFile]]:\n    \"\"\"Returns an iterator over (key, value) pairs in the directory.\n\n    Returns:\n        Iterator yielding tuples of (filename, file content)\n    \"\"\"\n    for key in self.keys():\n        yield (key, self[key])\n</code></pre>"},{"location":"reference/directory/#datamate.directory.Directory.from_df","title":"from_df  <code>classmethod</code>","text":"<pre><code>from_df(df, dtypes, *args, **kwargs)\n</code></pre> <p>Create a Directory from a DataFrame by splitting into column arrays.</p> <p>Each column is stored as a separate HDF5 array with specified dtype. This is different from storing the DataFrame directly, which uses CSV format.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>Source DataFrame</p> required <code>dtypes</code> <code>Dict[str, Any]</code> <p>Dictionary mapping column names to numpy dtypes</p> required <code>*args</code> <p>Additional arguments passed to <code>Directory</code> constructor</p> <code>()</code> <code>**kwargs</code> <p>Additional keyword arguments passed to <code>Directory</code> constructor</p> <code>{}</code> <p>Returns:</p> Type Description <code>T</code> <p><code>Directory</code> with each column stored as a separate array</p> <p>Examples:</p> <pre><code>df = pd.DataFrame({'a': [1, 2, 3], 'b': ['x', 'y', 'z']})\ndtypes = {'a': np.int64, 'b': 'S'}\n\n# Store columns as separate arrays\ndir1 = Directory.from_df(df, dtypes)\n# Results in:\n# dir1/\n#   \u251c\u2500\u2500 a.h5  # array([1, 2, 3])\n#   \u2514\u2500\u2500 b.h5  # array([b'x', b'y', b'z'])\n\n# Store as single CSV\ndir2 = Directory()\ndir2['data'] = df\n# Results in:\n# dir2/\n#   \u2514\u2500\u2500 data.csv\n</code></pre> Source code in <code>datamate/directory.py</code> <pre><code>@classmethod\ndef from_df(\n    cls: type[T], df: DataFrame, dtypes: Dict[str, Any], *args, **kwargs\n) -&gt; T:\n    \"\"\"Create a Directory from a DataFrame by splitting into column arrays.\n\n    Each column is stored as a separate HDF5 array with specified dtype.\n    This is different from storing the DataFrame directly, which uses CSV format.\n\n    Args:\n        df: Source DataFrame\n        dtypes: Dictionary mapping column names to numpy dtypes\n        *args: Additional arguments passed to `Directory` constructor\n        **kwargs: Additional keyword arguments passed to `Directory` constructor\n\n    Returns:\n        `Directory` with each column stored as a separate array\n\n    Examples:\n        ```python\n        df = pd.DataFrame({'a': [1, 2, 3], 'b': ['x', 'y', 'z']})\n        dtypes = {'a': np.int64, 'b': 'S'}\n\n        # Store columns as separate arrays\n        dir1 = Directory.from_df(df, dtypes)\n        # Results in:\n        # dir1/\n        #   \u251c\u2500\u2500 a.h5  # array([1, 2, 3])\n        #   \u2514\u2500\u2500 b.h5  # array([b'x', b'y', b'z'])\n\n        # Store as single CSV\n        dir2 = Directory()\n        dir2['data'] = df\n        # Results in:\n        # dir2/\n        #   \u2514\u2500\u2500 data.csv\n        ```\n    \"\"\"\n    directory = Directory.__new__(Directory, *args, **kwargs)\n    directory.update({\n        column: df[column].values.astype(dtypes[column]) for column in df.columns\n    })\n    return directory\n</code></pre>"},{"location":"reference/directory/#datamate.directory.Directory.update","title":"update","text":"<pre><code>update(other, suffix='')\n</code></pre> <p>Updates self with items of other and appends an optional suffix.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>Union[Dict, Directory]</code> <p>Dictionary or Directory to copy items from</p> required <code>suffix</code> <code>str</code> <p>Optional string to append to copied keys</p> <code>''</code> Source code in <code>datamate/directory.py</code> <pre><code>def update(self, other: Union[Dict, \"Directory\"], suffix: str = \"\") -&gt; None:\n    \"\"\"Updates self with items of other and appends an optional suffix.\n\n    Args:\n        other: Dictionary or Directory to copy items from\n        suffix: Optional string to append to copied keys\n    \"\"\"\n    for key in other:\n        if key + suffix not in self:\n            self[key + suffix] = other[key]\n</code></pre>"},{"location":"reference/directory/#datamate.directory.Directory.move","title":"move","text":"<pre><code>move(dst)\n</code></pre> <p>Moves directory to new location.</p> <p>Parameters:</p> Name Type Description Default <code>dst</code> <code>Union[str, Path]</code> <p>Destination path</p> required <p>Returns:</p> Type Description <code>Directory</code> <p>New <code>Directory</code> instance at the destination path</p> Source code in <code>datamate/directory.py</code> <pre><code>def move(self, dst: Union[str, Path]) -&gt; \"Directory\":\n    \"\"\"Moves directory to new location.\n\n    Args:\n        dst: Destination path\n\n    Returns:\n        New `Directory` instance at the destination path\n    \"\"\"\n    shutil.move(self.path, dst)\n    return Directory(dst)\n</code></pre>"},{"location":"reference/directory/#datamate.directory.Directory.rmtree","title":"rmtree","text":"<pre><code>rmtree(y_n=None)\n</code></pre> <p>Recursively deletes the directory after confirmation.</p> <p>Parameters:</p> Name Type Description Default <code>y_n</code> <code>Optional[str]</code> <p>Optional pre-supplied confirmation (\u2018y\u2019 or \u2018n\u2019). If not provided, will prompt user interactively</p> <code>None</code> Source code in <code>datamate/directory.py</code> <pre><code>def rmtree(self, y_n: Optional[str] = None) -&gt; None:\n    \"\"\"Recursively deletes the directory after confirmation.\n\n    Args:\n        y_n: Optional pre-supplied confirmation ('y' or 'n'). If not provided,\n            will prompt user interactively\n    \"\"\"\n    reply = y_n or input(f\"delete {self.path} recursively, y/n?\")\n    if reply.lower() == \"y\":\n        shutil.rmtree(self.path, ignore_errors=True)\n</code></pre>"},{"location":"reference/directory/#datamate.directory.Directory.__truediv__","title":"__truediv__","text":"<pre><code>__truediv__(other)\n</code></pre> <p>Implements path-like division operator for accessing entries.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>str</code> <p>Key to access</p> required <p>Returns:</p> Type Description <code>Any</code> <p>Same as <code>self[other]</code></p> Source code in <code>datamate/directory.py</code> <pre><code>def __truediv__(self, other: str) -&gt; Any:\n    \"\"\"Implements path-like division operator for accessing entries.\n\n    Args:\n        other: Key to access\n\n    Returns:\n        Same as `self[other]`\n    \"\"\"\n    return self.__getitem__(other)\n</code></pre>"},{"location":"reference/directory/#datamate.directory.Directory.__getitem__","title":"__getitem__","text":"<pre><code>__getitem__(key)\n</code></pre> <p>Returns <code>ArrayFile</code>, <code>Path</code>, or <code>Directory</code> corresponding to <code>self.path/key</code>.</p> <p>HDF5 files are returned as <code>ArrayFile</code>s, other files as <code>Path</code>s, and directories and nonexistent entries as (possibly empty) <code>Directory</code>s.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>Name of the entry to retrieve</p> required <p>Returns:</p> Type Description <code>Any</code> <p>The requested entry as an appropriate type</p> Note <p>Attribute access syntax is also supported, and occurrences of <code>__</code> in <code>key</code> are transformed into <code>.</code>, to support accessing encoded files as attributes (i.e. <code>Directory['name.ext']</code> is equivalent to <code>Directory.name__ext</code>).</p> Source code in <code>datamate/directory.py</code> <pre><code>def __getitem__(self, key: str) -&gt; Any:\n    \"\"\"Returns `ArrayFile`, `Path`, or `Directory` corresponding to `self.path/key`.\n\n    HDF5 files are returned as `ArrayFile`s, other files as `Path`s, and\n    directories and nonexistent entries as (possibly empty) `Directory`s.\n\n    Args:\n        key: Name of the entry to retrieve\n\n    Returns:\n        The requested entry as an appropriate type\n\n    Note:\n        Attribute access syntax is also supported, and occurrences of `__` in\n        `key` are transformed into `.`, to support accessing encoded files as\n        attributes (i.e. `Directory['name.ext']` is equivalent to\n        `Directory.name__ext`).\n    \"\"\"\n    # if context.in_memory:\n    #     return object.__getattribute__(self, key)\n\n    try:\n        # to catch cases where key is an index to a reference to an h5 file.\n        # this will yield a TypeError because Path / slice does not work.\n        path = self.path / key\n    except TypeError as e:\n        if not self.path.exists():\n            # we wanted to index an H5Dataset but we tried to index a Directory\n            # because the H5Dataset does not exist\n            raise FileNotFoundError(\n                f\"Indexing {self.path.name} at {key} not possible for\"\n                f\" Directory at {self.path.parent}. File \"\n                f\"{self.path.name}.h5 does not exist.\"\n            ) from e\n        raise e\n\n    # Return an array.\n    if path.with_suffix(\".h5\").is_file():\n        return _read_h5(path.with_suffix(\".h5\"))\n\n    # Return a csv\n    if path.with_suffix(\".csv\").is_file():\n        return pd.read_csv(path.with_suffix(\".csv\"))\n\n    # Return the path to a file.\n    elif path.is_file():\n        return path\n\n    # Return a subrecord\n    else:\n        return Directory(path)\n</code></pre>"},{"location":"reference/directory/#datamate.directory.Directory.__setitem__","title":"__setitem__","text":"<pre><code>__setitem__(key, val)\n</code></pre> <p>Writes an <code>ArrayFile</code>, <code>Path</code>, or <code>Directory</code> to <code>self.path/key</code></p> <p><code>np.ndarray</code>-like objects are written as <code>ArrayFiles</code>, <code>Path</code>-like objects are written as <code>Path</code>s, and string-keyed mappings are written as subDirectorys.</p> <p>Attribute access syntax is also supported, and occurrences of \u201c__\u201d in <code>key</code> are transformed into \u201c.\u201d, to support accessing encoded files as attributes (i.e. <code>Directory['name.ext'] = val</code> is equivalent to <code>Directory.name__ext = val</code>).</p> Source code in <code>datamate/directory.py</code> <pre><code>def __setitem__(self, key: str, val: object) -&gt; None:\n    \"\"\"\n    Writes an `ArrayFile`, `Path`, or `Directory` to `self.path/key`\n\n    `np.ndarray`-like objects are written as `ArrayFiles`, `Path`-like\n    objects are written as `Path`s, and string-keyed mappings are\n    written as subDirectorys.\n\n    Attribute access syntax is also supported, and occurrences of \"__\" in\n    `key` are transformed into \".\", to support accessing encoded files as\n    attributes (i.e. `Directory['name.ext'] = val` is equivalent to\n    `Directory.name__ext = val`).\n    \"\"\"\n    # if context.in_memory:\n    #     object.__setattr__(self, key, val)\n    #     return\n\n    path = self.path / key\n\n    # Copy an existing file or directory.\n    if isinstance(val, Path):\n        if os.path.isfile(val):\n            _copy_file(path, val)\n        elif os.path.isdir(val):\n            _copy_dir(path, val)\n\n    # Write a Directory instance\n    elif isinstance(val, Directory):\n        assert path.suffix == \"\"\n        # Create new directory with same type and config as source\n        new_dir = type(val)(path, config=val.config)\n        MutableMapping.update(new_dir, val)\n\n    # Write a mapping as a new Directory\n    elif isinstance(val, Mapping):\n        assert path.suffix == \"\"\n        MutableMapping.update(Directory(path), val)  # type: ignore\n\n    # Write a dataframe.\n    elif isinstance(val, pd.DataFrame):  # Use pd.DataFrame explicitly\n        assert path.suffix == \"\"\n        if not path.parent.exists():\n            path.parent.mkdir(parents=True, exist_ok=True)\n        val.to_csv(path.with_suffix(\".csv\"), index=False)\n\n    # Write an array.\n    else:\n        assert path.suffix == \"\"\n        if isinstance(val, H5Reader):\n            val = val[()]\n        try:\n            _write_h5(path.with_suffix(\".h5\"), val)\n        except TypeError as err:\n            raise TypeError(\n                format_tb(err.__traceback__)[0]\n                + err.args[0]\n                + f\"\\nYou're trying to store {val} which cannot be converted to \"\n                f\"h5-file in {path}.\"\n                + \"\\nFor reference of supported types, see \"\n                + \"https://docs.h5py.org/en/stable/faq.html?highlight=types\"\n                + \"#numpy-object-types\"\n                + \"\\nE.g. NumPy unicode strings must be converted to 'S' strings \"\n                + \"and back:\"\n                + \"\\nfoo.bar = array.astype('S') to store and foo.bar[:].\"\n                + \"astype('U') \"\n                + \"to retrieve.\"\n            ) from None\n\n    if self.config is not None and self.status == \"done\":\n        # Track if a Directory has been modified past __init__\n        self._modified_past_init(True)\n</code></pre>"},{"location":"reference/directory/#datamate.directory.Directory.__delitem__","title":"__delitem__","text":"<pre><code>__delitem__(key)\n</code></pre> <p>Deletes the entry at <code>self.path/key</code></p> <p>Attribute access syntax is also supported, and occurrences of \u201c__\u201d in <code>key</code> are transformed into \u201c.\u201d, to support accessing encoded files as attributes (i.e. <code>del Directory['name.ext']</code> is equivalent to <code>del Directory.name__ext</code>).</p> Source code in <code>datamate/directory.py</code> <pre><code>def __delitem__(self, key: str) -&gt; None:\n    \"\"\"\n    Deletes the entry at `self.path/key`\n\n    Attribute access syntax is also supported, and occurrences of \"__\" in\n    `key` are transformed into \".\", to support accessing encoded files as\n    attributes (i.e. `del Directory['name.ext']` is equivalent to\n    `del Directory.name__ext`).\n    \"\"\"\n    # if context.in_memory:\n    #     object.__delitem__(self, key)\n    #     return\n    path = self.path / key\n\n    # Delete an array file.\n    if path.with_suffix(\".h5\").is_file():\n        path.with_suffix(\".h5\").unlink()\n\n    # Delete a csv file.\n    if path.with_suffix(\".csv\").is_file():\n        path.with_suffix(\".csv\").unlink()\n\n    # Delete a non-array file.\n    elif path.is_file():\n        path.unlink()\n\n    # Delete a Directory.\n    else:\n        shutil.rmtree(path, ignore_errors=True)\n</code></pre>"},{"location":"reference/directory/#datamate.directory.Directory.__eq__","title":"__eq__","text":"<pre><code>__eq__(other)\n</code></pre> <p>Returns True if <code>self</code> and <code>other</code> are equal.</p> <p>Two Directories are equal if they have the same keys and the same values for each key.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>object</code> <p>Object to compare against</p> required <p>Returns:</p> Type Description <code>bool</code> <p>Whether the directories are equal</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If comparing <code>Directory</code> with incompatible type</p> Source code in <code>datamate/directory.py</code> <pre><code>def __eq__(self, other: object) -&gt; bool:\n    \"\"\"Returns True if `self` and `other` are equal.\n\n    Two Directories are equal if they have the same keys and the same\n    values for each key.\n\n    Args:\n        other: Object to compare against\n\n    Returns:\n        Whether the directories are equal\n\n    Raises:\n        ValueError: If comparing `Directory` with incompatible type\n    \"\"\"\n    if not isinstance(other, Directory):\n        raise ValueError(f\"Cannot compare Directory to {type(other)}\")\n\n    if self.path == other.path:\n        return True\n\n    if self.path != other.path:\n        diff = DirectoryDiff(self, other)\n        return diff.equal(fail=False)\n</code></pre>"},{"location":"reference/directory/#datamate.directory.Directory.__neq__","title":"__neq__","text":"<pre><code>__neq__(other)\n</code></pre> <p>Returns True if directories are not equal.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>object</code> <p>Object to compare against</p> required <p>Returns:</p> Type Description <code>bool</code> <p>Whether the directories are not equal</p> Source code in <code>datamate/directory.py</code> <pre><code>def __neq__(self, other: object) -&gt; bool:\n    \"\"\"Returns True if directories are not equal.\n\n    Args:\n        other: Object to compare against\n\n    Returns:\n        Whether the directories are not equal\n    \"\"\"\n    return not self.__eq__(other)\n</code></pre>"},{"location":"reference/directory/#datamate.directory.Directory.diff","title":"diff","text":"<pre><code>diff(other)\n</code></pre> <p>Returns a dictionary of differences between this directory and another.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>Directory</code> <p>Directory to compare against</p> required <p>Returns:</p> Type Description <code>Dict[str, List[str]]</code> <p>Dictionary with two keys - the name of self and other. Values are lists of</p> <code>Dict[str, List[str]]</code> <p>strings describing differences between corresponding entries.</p> Source code in <code>datamate/directory.py</code> <pre><code>def diff(self, other: \"Directory\") -&gt; Dict[str, List[str]]:\n    \"\"\"Returns a dictionary of differences between this directory and another.\n\n    Args:\n        other: Directory to compare against\n\n    Returns:\n        Dictionary with two keys - the name of self and other. Values are lists of\n        strings describing differences between corresponding entries.\n    \"\"\"\n    diff = DirectoryDiff(self, other)\n    return diff.diff()\n</code></pre>"},{"location":"reference/directory/#datamate.directory.Directory.extend","title":"extend","text":"<pre><code>extend(key, val)\n</code></pre> <p>Extends an array, file or directory at the given key.</p> <p>Extending arrays performs concatenation along the first axis, extending files performs byte-level concatenation, and extending directories extends their fields.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>Name of the entry to extend</p> required <code>val</code> <code>object</code> <p>Value to append to the existing entry. Can be <code>np.ndarray</code>, <code>Path</code>, <code>Directory</code>, or <code>Mapping</code></p> required Note <p>Files corresponding to <code>self[key]</code> are created if they do not already exist.</p> Source code in <code>datamate/directory.py</code> <pre><code>def extend(self, key: str, val: object) -&gt; None:\n    \"\"\"Extends an array, file or directory at the given key.\n\n    Extending arrays performs concatenation along the first axis,\n    extending files performs byte-level concatenation, and\n    extending directories extends their fields.\n\n    Args:\n        key: Name of the entry to extend\n        val: Value to append to the existing entry. Can be `np.ndarray`, `Path`,\n            `Directory`, or `Mapping`\n\n    Note:\n        Files corresponding to `self[key]` are created if they do not already exist.\n    \"\"\"\n    # if context.in_memory:\n    #     self.__setitem__(key, np.append(self.__getitem__(key), val, axis=0))\n\n    path = self.path / key\n\n    # Append an existing file.\n    if isinstance(val, Path):\n        assert path.suffix != \"\"\n        _extend_file(path, val)\n\n    # Append a subDirectory.\n    elif isinstance(val, (Mapping, Directory)):\n        assert path.suffix == \"\"\n        for k in val:\n            Directory(path).extend(k, val[k])\n\n    elif isinstance(val, pd.DataFrame):\n        assert path.suffix == \"\"\n        if path.with_suffix(\".csv\").is_file():\n            old_df = pd.read_csv(path.with_suffix(\".csv\"))\n            new_df = pd.concat([old_df, val], axis=0)\n        else:\n            new_df = val\n        new_df.to_csv(path.with_suffix(\".csv\"), index=False)\n\n    # Append an array.\n    else:\n        assert path.suffix == \"\"\n        if isinstance(val, H5Reader):\n            val = val[()]\n        _extend_h5(path.with_suffix(\".h5\"), val)\n\n    if self.config is not None and self.status == \"done\":\n        # Track if a Directory has been modified past __init__\n        self._modified_past_init(True)\n</code></pre>"},{"location":"reference/directory/#datamate.directory.Directory.tree","title":"tree","text":"<pre><code>tree(\n    level=-1,\n    length_limit=None,\n    verbose=True,\n    last_modified=True,\n    limit_to_directories=False,\n)\n</code></pre> <p>Prints a tree representation of the directory structure.</p> <p>Parameters:</p> Name Type Description Default <code>level</code> <code>int</code> <p>Maximum depth to display (-1 for unlimited)</p> <code>-1</code> <code>length_limit</code> <code>Optional[int]</code> <p>Maximum number of entries to show per directory</p> <code>None</code> <code>verbose</code> <code>bool</code> <p>Whether to show detailed information</p> <code>True</code> <code>last_modified</code> <code>bool</code> <p>Whether to show last modification times</p> <code>True</code> <code>limit_to_directories</code> <code>bool</code> <p>Whether to only show directories</p> <code>False</code> Source code in <code>datamate/directory.py</code> <pre><code>def tree(\n    self,\n    level: int = -1,\n    length_limit: Optional[int] = None,\n    verbose: bool = True,\n    last_modified: bool = True,\n    limit_to_directories: bool = False,\n) -&gt; None:\n    \"\"\"Prints a tree representation of the directory structure.\n\n    Args:\n        level: Maximum depth to display (-1 for unlimited)\n        length_limit: Maximum number of entries to show per directory\n        verbose: Whether to show detailed information\n        last_modified: Whether to show last modification times\n        limit_to_directories: Whether to only show directories\n    \"\"\"\n    print(\n        tree(\n            self.path,\n            level=level,\n            length_limit=length_limit,\n            last_modified=last_modified,\n            verbose=verbose,\n            limit_to_directories=limit_to_directories,\n        )\n    )\n</code></pre>"},{"location":"reference/directory/#datamate.directory.Directory.__manual_config","title":"__manual_config","text":"<pre><code>__manual_config(config, status=None)\n</code></pre> <p>Overriding config stored in _meta.yaml.</p> <p>config (Dict): update for meta.config status (str): status if config did not exist before, i.e. _overrid_config     is used to store a _meta.yaml for the first time instead of build.</p> Source code in <code>datamate/directory.py</code> <pre><code>def __manual_config(self, config, status=None):\n    \"\"\"Overriding config stored in _meta.yaml.\n\n    config (Dict): update for meta.config\n    status (str): status if config did not exist before, i.e. _overrid_config\n        is used to store a _meta.yaml for the first time instead of build.\n    \"\"\"\n    meta_path = self.path / \"_meta.yaml\"\n\n    current_config = self.config\n    config = namespacify(config)\n    if current_config is not None:\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"always\")\n            warnings.warn(\n                (\n                    f\"Overriding config. Diff is:\"\n                    f'{config.diff(current_config, name1=\"passed\", name2=\"stored\")}'\n                ),\n                ConfigWarning,\n                stacklevel=2,\n            )\n        write_meta(path=meta_path, config=config, status=\"manually written\")\n    else:\n        write_meta(path=meta_path, config=config, status=status or self.status)\n</code></pre>"},{"location":"reference/directory/#datamate.directory.Directory.check_size","title":"check_size","text":"<pre><code>check_size(\n    warning_at=20 * 1024**3,\n    print_size=False,\n    *,\n    raise_on_warning=False,\n)\n</code></pre> <p>Checks the total size of the directory.</p> <p>Parameters:</p> Name Type Description Default <code>warning_at</code> <code>int</code> <p>Size in bytes at which to issue a warning</p> <code>20 * 1024 ** 3</code> <code>print_size</code> <code>bool</code> <p>Whether to print the directory size</p> <code>False</code> <code>raise_on_warning</code> <code>bool</code> <p>Whether to raise exception instead of warning</p> <code>False</code> <p>Returns:</p> Type Description <code>int</code> <p>Total size in bytes</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>if directory size exceeds warning_at and raise_on_warning is True</p> Source code in <code>datamate/directory.py</code> <pre><code>def check_size(\n    self,\n    warning_at: int = 20 * 1024**3,  # 20GB\n    print_size: bool = False,\n    *,\n    raise_on_warning: bool = False,\n) -&gt; int:\n    \"\"\"Checks the total size of the directory.\n\n    Args:\n        warning_at: Size in bytes at which to issue a warning\n        print_size: Whether to print the directory size\n        raise_on_warning: Whether to raise exception instead of warning\n\n    Returns:\n        Total size in bytes\n\n    Raises:\n        ValueError: if directory size exceeds warning_at and raise_on_warning\n            is True\n    \"\"\"\n    size = check_size(self.path, warning_at, print_size)\n    if raise_on_warning and size &gt; warning_at:\n        raise ValueError(f\"Directory size {size} exceeds limit {warning_at}\")\n    return size\n</code></pre>"},{"location":"reference/directory/#datamate.directory.Directory.to_df","title":"to_df","text":"<pre><code>to_df(dtypes=None)\n</code></pre> <p>Reconstruct a DataFrame from HDF5 column arrays in this directory.</p> <p>Combines all equal-length, single-dimensional HDF5 datasets into DataFrame columns. Results are cached to avoid expensive recomputation.</p> <p>Parameters:</p> Name Type Description Default <code>dtypes</code> <code>Optional[Dict[str, Any]]</code> <p>Optional dictionary mapping column names to numpy dtypes</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p><code>DataFrame</code> reconstructed from HDF5 column arrays</p> Note <p>This is the complement to <code>from_df()</code>. While direct DataFrame assignment stores as CSV, <code>from_df()</code> splits columns into HDF5 arrays which can be recombined using this method.</p> Source code in <code>datamate/directory.py</code> <pre><code>def to_df(self, dtypes: Optional[Dict[str, Any]] = None) -&gt; DataFrame:\n    \"\"\"Reconstruct a DataFrame from HDF5 column arrays in this directory.\n\n    Combines all equal-length, single-dimensional HDF5 datasets into\n    DataFrame columns. Results are cached to avoid expensive recomputation.\n\n    Args:\n        dtypes: Optional dictionary mapping column names to numpy dtypes\n\n    Returns:\n        `DataFrame` reconstructed from HDF5 column arrays\n\n    Note:\n        This is the complement to `from_df()`. While direct DataFrame assignment\n        stores as CSV, `from_df()` splits columns into HDF5 arrays which can be\n        recombined using this method.\n    \"\"\"\n    try:\n        return object.__getattribute__(self, \"_as_df\")\n    except AttributeError:\n        object.__setattr__(self, \"_as_df\", directory_to_df(self, dtypes))\n        return self.to_df()\n</code></pre>"},{"location":"reference/directory/#datamate.directory.Directory.to_dict","title":"to_dict","text":"<pre><code>to_dict()\n</code></pre> <p>Returns a DataFrame from all equal length, single-dim .h5 datasets in self.path.</p> Source code in <code>datamate/directory.py</code> <pre><code>def to_dict(self) -&gt; DataFrame:\n    \"\"\"\n    Returns a DataFrame from all equal length, single-dim .h5 datasets in self.path.\n    \"\"\"\n    # to cache the dict that is expensive to create.\n    try:\n        return object.__getattribute__(self, \"_as_dict\")\n    except AttributeError:\n        object.__setattr__(self, \"_as_dict\", directory_to_dict(self))\n        return self.to_dict()\n</code></pre>"},{"location":"reference/directory/#datamate.directory.Directory.mtime","title":"mtime","text":"<pre><code>mtime()\n</code></pre> <p>Returns the last modification time of the directory.</p> <p>Returns:</p> Type Description <code>datetime</code> <p>Datetime object representing last modification time</p> Source code in <code>datamate/directory.py</code> <pre><code>def mtime(self) -&gt; datetime.datetime:\n    \"\"\"Returns the last modification time of the directory.\n\n    Returns:\n        Datetime object representing last modification time\n    \"\"\"\n    return datetime.datetime.fromtimestamp(self.path.stat().st_mtime)\n</code></pre>"},{"location":"reference/directory/#datamate.directory.NonExistingDirectory","title":"NonExistingDirectory","text":"<p>               Bases: <code>type</code></p> <p>Directory metaclass to allow create non-existing Directory instances.</p> Source code in <code>datamate/directory.py</code> <pre><code>class NonExistingDirectory(type):\n    \"\"\"Directory metaclass to allow create non-existing Directory instances.\"\"\"\n\n    def __call__(cls, *args, **kwargs):\n        return cls.__new__(cls, *args, **kwargs)\n</code></pre>"},{"location":"reference/io/","title":"IO","text":""},{"location":"reference/io/#datamate.io","title":"datamate.io","text":"<p>Module for handling file I/O operations for Directory objects.</p> <p>This module provides functionality for reading, writing, and manipulating HDF5 files and directories.</p>"},{"location":"reference/io/#datamate.io.ArrayFile","title":"ArrayFile","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol for single-array HDF5 file interface.</p> <p>Attributes:</p> Name Type Description <code>path</code> <code>Path</code> <p>Path to the HDF5 file.</p> <code>shape</code> <code>Tuple[int, ...]</code> <p>Shape of the array data.</p> <code>dtype</code> <code>dtype</code> <p>NumPy dtype of the array data.</p> Source code in <code>datamate/io.py</code> <pre><code>@runtime_checkable\nclass ArrayFile(Protocol):\n    \"\"\"Protocol for single-array HDF5 file interface.\n\n    Attributes:\n        path: Path to the HDF5 file.\n        shape: Shape of the array data.\n        dtype: NumPy dtype of the array data.\n    \"\"\"\n\n    path: Path\n    shape: Tuple[int, ...]\n    dtype: np.dtype\n\n    def __getitem__(self, key: Any) -&gt; Any: ...\n    def __len__(self) -&gt; int: ...\n    def __getattr__(self, key: str) -&gt; Any: ...\n</code></pre>"},{"location":"reference/io/#datamate.io.H5Reader","title":"H5Reader","text":"<p>               Bases: <code>ArrayFile</code></p> <p>Wrapper around HDF5 read operations with safe file handle management.</p> <p>Ensures file handles are only open during access operations to prevent resource leaks.</p> <p>Attributes:</p> Name Type Description <code>path</code> <p>Path to the HDF5 file.</p> <code>shape</code> <p>Shape of the array data.</p> <code>dtype</code> <p>NumPy dtype of the array data.</p> <code>n_retries</code> <p>Number of retry attempts for file operations.</p> Source code in <code>datamate/io.py</code> <pre><code>class H5Reader(ArrayFile):\n    \"\"\"Wrapper around HDF5 read operations with safe file handle management.\n\n    Ensures file handles are only open during access operations to prevent resource leaks.\n\n    Attributes:\n        path: Path to the HDF5 file.\n        shape: Shape of the array data.\n        dtype: NumPy dtype of the array data.\n        n_retries: Number of retry attempts for file operations.\n    \"\"\"\n\n    def __init__(\n        self, path: Path, assert_swmr: bool = True, n_retries: int = 10\n    ) -&gt; None:\n        self.path = Path(path)\n        with h5.File(self.path, mode=\"r\", libver=\"latest\", swmr=True) as f:\n            if assert_swmr:\n                assert f.swmr_mode, \"File is not in SWMR mode.\"\n            assert \"data\" in f\n            self.shape = f[\"data\"].shape\n            self.dtype = f[\"data\"].dtype\n        self.n_retries = n_retries\n\n    def __getitem__(self, key):\n        for retry_count in range(self.n_retries):\n            try:\n                with h5.File(self.path, mode=\"r\", libver=\"latest\", swmr=True) as f:\n                    data = f[\"data\"][key]\n                break\n            except Exception as e:\n                if retry_count == self.n_retries - 1:\n                    raise e\n                sleep(0.1)\n        return data\n\n    def __len__(self):\n        return self.shape[0]\n\n    def __getattr__(self, key):\n        # get attribute from underlying h5.Dataset object\n        for retry_count in range(self.n_retries):\n            try:\n                with h5.File(self.path, mode=\"r\", libver=\"latest\", swmr=True) as f:\n                    value = getattr(f[\"data\"], key, None)\n                break\n            except Exception as e:\n                if retry_count == self.n_retries - 1:\n                    raise e\n                sleep(0.1)\n        if value is None:\n            raise AttributeError(f\"Attribute {key} not found.\")\n        # wrap callable attributes to open file before calling function\n        if callable(value):\n\n            def safe_wrapper(*args, **kwargs):\n                # not trying `n_retries` times here, just for simplicity\n                with h5.File(self.path, mode=\"r\", libver=\"latest\", swmr=True) as f:\n                    output = getattr(f[\"data\"], key)(*args, **kwargs)\n                return output\n\n            return safe_wrapper\n        # otherwise just return value\n        else:\n            return value\n</code></pre>"},{"location":"reference/io/#datamate.io.directory_to_df","title":"directory_to_df","text":"<pre><code>directory_to_df(directory, dtypes=None)\n</code></pre> <p>Convert a directory to a pandas DataFrame.</p> <p>Creates a DataFrame from HDF5 datasets in the directory. Single-element datasets are broadcast to match the most common length.</p> <p>Parameters:</p> Name Type Description Default <code>directory</code> <code>Directory</code> <p>Directory object containing HDF5 datasets.</p> required <code>dtypes</code> <code>Optional[Dict[str, dtype]]</code> <p>Optional mapping of column names to NumPy dtypes.</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame containing the directory data.</p> Example <pre><code>dir = Directory(\"path/to/dir\")\ndf = directory_to_df(dir, {\"col1\": np.float32})\n</code></pre> Source code in <code>datamate/io.py</code> <pre><code>def directory_to_df(\n    directory: \"Directory\", dtypes: Optional[Dict[str, np.dtype]] = None\n) -&gt; DataFrame:\n    \"\"\"Convert a directory to a pandas DataFrame.\n\n    Creates a DataFrame from HDF5 datasets in the directory. Single-element datasets\n    are broadcast to match the most common length.\n\n    Args:\n        directory: Directory object containing HDF5 datasets.\n        dtypes: Optional mapping of column names to NumPy dtypes.\n\n    Returns:\n        DataFrame containing the directory data.\n\n    Example:\n        ```python\n        dir = Directory(\"path/to/dir\")\n        df = directory_to_df(dir, {\"col1\": np.float32})\n        ```\n    \"\"\"\n    from .utils import byte_to_str\n\n    df_dict = {\n        key: getattr(directory, key)[...]\n        for key in list(directory.keys())\n        if isinstance(getattr(directory, key), H5Reader)\n    }\n\n    # Get the lengths of all datasets.\n    nelements = {k: len(v) or 1 for k, v in df_dict.items()}\n\n    lengths, counts = np.unique([val for val in nelements.values()], return_counts=True)\n    most_frequent_length = lengths[np.argmax(counts)]\n\n    # If there are single element datasets, just create a new column of most_frequent_length and put the value in each row.\n    if lengths.min() == 1:\n        for k, v in nelements.items():\n            if v == 1:\n                df_dict[k] = df_dict[k].repeat(most_frequent_length)\n\n    df_dict = byte_to_str(df_dict)\n\n    if dtypes is not None:\n        df_dict = {\n            k: np.array(v).astype(dtypes[k]) for k, v in df_dict.items() if k in dtypes\n        }\n    return DataFrame.from_dict(\n        {k: v.tolist() if v.ndim &gt; 1 else v for k, v in df_dict.items()}\n    )\n</code></pre>"},{"location":"reference/metadata/","title":"Metadata","text":""},{"location":"reference/metadata/#datamate.metadata","title":"datamate.metadata","text":"<p>Module for handling metadata reading, writing and validation for Directory objects.</p>"},{"location":"reference/metadata/#datamate.metadata.MetadataError","title":"MetadataError","text":"<p>               Bases: <code>ValueError</code></p> <p>Base class for metadata-related errors.</p> Source code in <code>datamate/metadata.py</code> <pre><code>class MetadataError(ValueError):\n    \"\"\"Base class for metadata-related errors.\"\"\"\n\n    pass\n</code></pre>"},{"location":"reference/metadata/#datamate.metadata.MetadataParseError","title":"MetadataParseError","text":"<p>               Bases: <code>MetadataError</code></p> <p>Raised when metadata YAML cannot be parsed.</p> Source code in <code>datamate/metadata.py</code> <pre><code>class MetadataParseError(MetadataError):\n    \"\"\"Raised when metadata YAML cannot be parsed.\"\"\"\n\n    pass\n</code></pre>"},{"location":"reference/metadata/#datamate.metadata.MetadataValidationError","title":"MetadataValidationError","text":"<p>               Bases: <code>MetadataError</code></p> <p>Raised when metadata structure is invalid.</p> Source code in <code>datamate/metadata.py</code> <pre><code>class MetadataValidationError(MetadataError):\n    \"\"\"Raised when metadata structure is invalid.\"\"\"\n\n    pass\n</code></pre>"},{"location":"reference/metadata/#datamate.metadata.read_meta","title":"read_meta","text":"<pre><code>read_meta(path, retries=5)\n</code></pre> <p>Read and validate metadata from a directory\u2019s <code>_meta.yaml</code> file.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>Directory path containing <code>_meta.yaml</code></p> required <code>retries</code> <code>int</code> <p>Number of retry attempts for transient failures</p> <code>5</code> <p>Returns:</p> Type Description <code>Namespace</code> <p>Namespace containing validated metadata with <code>config</code> and <code>status</code></p> <p>Raises:</p> Type Description <code>MetadataParseError</code> <p>If YAML parsing fails</p> <code>MetadataValidationError</code> <p>If metadata structure is invalid</p> <code>FileNotFoundError</code> <p>If <code>_meta.yaml</code> doesn\u2019t exist</p> <code>NotADirectoryError</code> <p>If path is not a directory</p> Note <p>Returns default metadata (empty config, status=\u201ddone\u201d) for non-existent paths</p> Source code in <code>datamate/metadata.py</code> <pre><code>def read_meta(path: Path, retries: int = 5) -&gt; Namespace:\n    \"\"\"Read and validate metadata from a directory's `_meta.yaml` file.\n\n    Args:\n        path: Directory path containing `_meta.yaml`\n        retries: Number of retry attempts for transient failures\n\n    Returns:\n        Namespace containing validated metadata with `config` and `status`\n\n    Raises:\n        MetadataParseError: If YAML parsing fails\n        MetadataValidationError: If metadata structure is invalid\n        FileNotFoundError: If `_meta.yaml` doesn't exist\n        NotADirectoryError: If path is not a directory\n\n    Note:\n        Returns default metadata (empty config, status=\"done\") for non-existent paths\n    \"\"\"\n    meta_path = path / \"_meta.yaml\"\n\n    try:\n        yaml = YAML()\n        with open(meta_path, \"r\") as f:\n            try:\n                meta = yaml.load(f)\n            except Exception as e:\n                raise MetadataParseError(f\"Failed to parse {meta_path}: {e}\") from e\n\n        meta = namespacify(meta)\n\n        # Validate metadata structure\n        if not isinstance(meta, Namespace):\n            raise MetadataValidationError(\n                f\"Metadata must be a Namespace, got {type(meta)}\"\n            )\n\n        if not hasattr(meta, \"config\"):\n            raise MetadataValidationError(\n                f\"Missing required 'config' field in {meta_path}\"\n            )\n\n        if not isinstance(meta.config, Namespace):\n            raise MetadataValidationError(\n                f\"'config' must be a Namespace in {meta_path}\"\n            )\n\n        if not hasattr(meta, \"status\"):\n            raise MetadataValidationError(\n                f\"Missing required 'status' field in {meta_path}\"\n            )\n\n        if not isinstance(meta.status, str):\n            raise MetadataValidationError(f\"'status' must be a string in {meta_path}\")\n\n        # Handle legacy 'spec' field\n        if hasattr(meta, \"spec\"):\n            if not isinstance(meta.spec, Namespace):\n                raise MetadataValidationError(\n                    f\"Legacy 'spec' must be a Namespace in {meta_path}\"\n                )\n            warnings.warn(\n                f\"Directory {path} uses legacy 'spec' instead of 'meta'. Please update.\",\n                DeprecationWarning,\n                stacklevel=2,\n            )\n            meta[\"config\"] = meta.pop(\"spec\")\n\n        return meta\n\n    except (MetadataError, AssertionError) as e:\n        if retries &gt; 0:\n            sleep(0.1)\n            return read_meta(path, retries=retries - 1)\n        raise e\n\n    except (FileNotFoundError, NotADirectoryError):\n        # Return default metadata for non-existent or invalid paths\n        return Namespace(config=None, status=\"done\")\n</code></pre>"},{"location":"reference/metadata/#datamate.metadata.write_meta","title":"write_meta","text":"<pre><code>write_meta(path, config=None, status=None, **kwargs)\n</code></pre> <p>Write metadata to a YAML file.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>Path to write the metadata file</p> required <code>config</code> <code>Optional[Dict[str, Any]]</code> <p>Configuration dictionary to store</p> <code>None</code> <code>status</code> <code>Optional[Literal['done', 'error', 'running']]</code> <p>Status string indicating directory state</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional metadata fields to include</p> <code>{}</code> Note <p>Supports serialization of numpy types (arrays, integers, floats)</p> Source code in <code>datamate/metadata.py</code> <pre><code>def write_meta(\n    path: Path,\n    config: Optional[Dict[str, Any]] = None,\n    status: Optional[Literal[\"done\", \"error\", \"running\"]] = None,\n    **kwargs: Any,\n) -&gt; None:\n    \"\"\"Write metadata to a YAML file.\n\n    Args:\n        path: Path to write the metadata file\n        config: Configuration dictionary to store\n        status: Status string indicating directory state\n        **kwargs: Additional metadata fields to include\n\n    Note:\n        Supports serialization of numpy types (arrays, integers, floats)\n    \"\"\"\n    yaml = YAML()\n\n    # support dumping numpy objects\n    def represent_numpy_float(self, value):\n        return self.represent_float(float(value))\n\n    def represent_numpy_int(self, value):\n        return self.represent_int(int(value))\n\n    def represent_numpy_array(self, value):\n        return self.represent_sequence(value.tolist())\n\n    yaml.Representer.add_multi_representer(np.ndarray, represent_numpy_array)\n    yaml.Representer.add_multi_representer(np.floating, represent_numpy_float)\n    yaml.Representer.add_multi_representer(np.integer, represent_numpy_int)\n\n    # This allows directory types to be dumped to yaml\n    config = _identify_elements(config)\n    kwargs = _identify_elements(kwargs)\n\n    # dump config to yaml\n    with open(path, \"w\") as f:\n        yaml.dump({\"config\": config, \"status\": status, **kwargs}, f)\n</code></pre>"},{"location":"reference/namespace/","title":"Namespace","text":""},{"location":"reference/namespace/#datamate.namespaces","title":"datamate.namespaces","text":"<p>Module for handling nested dictionary-like objects with attribute access support.</p> <p>This module provides the <code>Namespace</code> class and related utilities for working with nested dictionary-like objects that support both attribute and key-based access.</p>"},{"location":"reference/namespace/#datamate.namespaces.Namespace","title":"Namespace","text":"<p>               Bases: <code>Dict[str, Any]</code></p> <p>A dictionary subclass supporting both attribute and item access.</p> <p>Attributes:</p> Name Type Description <code>__dict__</code> <code>Dict[str, Any]</code> <p>The underlying dictionary storage.</p> <p>Examples:</p> <pre><code>ns = Namespace({\"a\": 1, \"b\": {\"c\": 2}})\nassert ns.a == 1\nassert ns.b.c == 2\n</code></pre> Source code in <code>datamate/namespaces.py</code> <pre><code>class Namespace(Dict[str, Any]):\n    \"\"\"\n    A dictionary subclass supporting both attribute and item access.\n\n    Attributes:\n        __dict__ (Dict[str, Any]): The underlying dictionary storage.\n\n    Examples:\n        ```python\n        ns = Namespace({\"a\": 1, \"b\": {\"c\": 2}})\n        assert ns.a == 1\n        assert ns.b.c == 2\n        ```\n    \"\"\"\n\n    def __dir__(self) -&gt; List[str]:\n        \"\"\"Return list of valid attributes including dictionary keys.\"\"\"\n        return list(set([*dict.__dir__(self), *dict.__iter__(self)]))\n\n    def __getattr__(self, key: str) -&gt; Any:\n        try:\n            return dict.__getitem__(self, key)\n        except KeyError:\n            raise AttributeError(key)\n\n    def __setattr__(self, key: str, val: object) -&gt; None:\n        dict.__setitem__(self, key, val)\n\n    def __delattr__(self, key: str) -&gt; None:\n        dict.__delitem__(self, key)\n\n    @property\n    def __dict__(self) -&gt; dict:  # type: ignore\n        return self\n\n    def __repr__(self) -&gt; str:\n        def single_line_repr(elem: object) -&gt; str:\n            if isinstance(elem, list):\n                return \"[\" + \", \".join(map(single_line_repr, elem)) + \"]\"\n            elif isinstance(elem, Namespace):\n                return (\n                    f\"{elem.__class__.__name__}(\"\n                    + \", \".join(f\"{k}={single_line_repr(v)}\" for k, v in elem.items())\n                    + \")\"\n                )\n            else:\n                return repr(elem).replace(\"\\n\", \" \")\n\n        def repr_in_context(elem: object, curr_col: int, indent: int) -&gt; str:\n            sl_repr = single_line_repr(elem)\n            if len(sl_repr) &lt;= 80 - curr_col:\n                return sl_repr\n            elif isinstance(elem, list):\n                return (\n                    \"[\\n\"\n                    + \" \" * (indent + 2)\n                    + (\",\\n\" + \" \" * (indent + 2)).join(\n                        repr_in_context(e, indent + 2, indent + 2) for e in elem\n                    )\n                    + \"\\n\"\n                    + \" \" * indent\n                    + \"]\"\n                )\n            elif isinstance(elem, Namespace):\n                return (\n                    f\"{elem.__class__.__name__}(\\n\"\n                    + \" \" * (indent + 2)\n                    + (\",\\n\" + \" \" * (indent + 2)).join(\n                        f\"{k} = \" + repr_in_context(v, indent + 5 + len(k), indent + 2)\n                        for k, v in elem.items()\n                    )\n                    + \"\\n\"\n                    + \" \" * indent\n                    + \")\"\n                )\n            else:\n                return repr(elem)\n\n        return repr_in_context(self, 0, 0)\n\n    def __eq__(self, other):\n        return all_true(compare(namespacify(self), namespacify(other)))\n\n    def __ne__(self, other):\n        return not self.__eq__(other)\n\n    def without(self, key: str) -&gt; \"Namespace\":\n        \"\"\"\n        Return a copy of the namespace without the specified key.\n\n        Args:\n            key: Key to remove from the namespace.\n\n        Returns:\n            New namespace without the specified key.\n        \"\"\"\n        _copy = self.deepcopy()\n        _copy.pop(key)\n        return _copy\n\n    def is_superset(self, other):\n        return is_subset(self, other)\n\n    def is_subset(self, other: Union[Dict, \"Namespace\"]) -&gt; bool:\n        \"\"\"\n        Check if this namespace is a subset of another.\n\n        Args:\n            other: The potential superset to compare against.\n\n        Returns:\n            True if this namespace is a subset of other.\n        \"\"\"\n        return is_superset(other, self)\n\n    def is_disjoint(self, other_dict):\n        \"\"\"\n        Check whether another dictionary is disjoint with respect to this one.\n\n        Two dictionaries are considered disjoint if they have no common keys.\n\n        Parameters:\n        other_dict (dict): The other dictionary to check for disjointness.\n\n        Returns:\n        bool: True if the other dictionary is disjoint with respect to this one,\n              False otherwise.\n        \"\"\"\n        return is_disjoint(self, other_dict)\n\n    def to_df(self, name: str = \"\", seperator: str = \".\") -&gt; \"pd.DataFrame\":  # type: ignore\n        \"\"\"\n        Convert namespace to flattened DataFrame.\n\n        Args:\n            name: Column name for the resulting DataFrame.\n            seperator: Character to use for separating nested keys.\n\n        Returns:\n            Flattened DataFrame representation.\n        \"\"\"\n        as_dict = self.to_dict()  # namespace need deepcopy method\n        df = pd.json_normalize(as_dict, sep=seperator).T\n        if name:\n            df = df.rename({0: name}, axis=1)\n        return df\n\n    def diff(\n        self, other: \"Namespace\", name1: str = \"self\", name2: str = \"other\"\n    ) -&gt; \"Namespace\":\n        \"\"\"\n        Compare two namespaces and return their differences.\n\n        Args:\n            other: The namespace to compare against.\n            name1: Label for the current namespace in the diff output.\n            name2: Label for the other namespace in the diff output.\n\n        Returns:\n            A namespace containing the differences, with + indicating additions,\n            - indicating deletions, and \u2260 indicating changes.\n\n        Examples:\n            ```python\n            ns1 = Namespace({\"a\": 1, \"b\": 2})\n            ns2 = Namespace({\"b\": 3, \"c\": 4})\n            diff = ns1.diff(ns2)\n            # Returns: {\n            #   \"self\": [\"+a: 1\", \"\u2260b: 2\", \"-c\"],\n            #   \"other\": [\"-a\", \"\u2260b: 3\", \"+c: 4\"]\n            # }\n            ```\n        \"\"\"\n        if self is None or other is None:\n            return Namespace({name1: self, name2: other})\n\n        _self = namespacify(self)\n        other = namespacify(other)\n        diff1: List[str] = []\n        diff2: List[str] = []\n        diff = {name1: diff1, name2: diff2}\n\n        def _diff(self: Namespace, other: Namespace, parent: str = \"\") -&gt; None:\n            for k, v in self.items():\n                if k not in other:\n                    _diff1 = f\"+{parent}.{k}: {v}\" if parent else f\"+{k}: {v}\"\n                    _diff2 = f\"-{parent}.{k}\" if parent else f\"-{k}\"\n                    diff1.append(_diff1)\n                    diff2.append(_diff2)\n                elif v == other[k]:\n                    pass\n                elif isinstance(v, Namespace):\n                    _parent = f\"{parent}.{k}\" if parent else f\"{k}\"\n                    _diff(v, other[k], parent=_parent)\n                else:\n                    _diff1 = f\"\u2260{parent}.{k}: {v}\" if parent else f\"\u2260{k}: {v}\"\n                    _diff2 = (\n                        f\"\u2260{parent}.{k}: {other[k]}\" if parent else f\"\u2260{k}: {other[k]}\"\n                    )\n                    diff1.append(_diff1)\n                    diff2.append(_diff2)\n\n            for k, v in other.items():\n                if k not in self:\n                    _diff1 = f\"-{parent}.{k}\" if parent else f\"-{k}\"\n                    _diff2 = f\"+{parent}.{k}: {v}\" if parent else f\"+{k}: {v}\"\n                    diff1.append(_diff1)\n                    diff2.append(_diff2)\n\n        _diff(_self, other)\n        return namespacify(diff)\n\n    def walk(self) -&gt; Iterator[Tuple[str, Any]]:\n        \"\"\"\n        Recursively walk through the namespace and yield key-value pairs.\n\n        Yields:\n            Tuples of (key, value) for each item in the namespace, including nested items.\n\n        Examples:\n            ```python\n            ns = Namespace({\"a\": 1, \"b\": {\"c\": 2}})\n            for key, value in ns.walk():\n                print(f\"{key}: {value}\")\n            # Prints:\n            # a: 1\n            # b: {'c': 2}\n            # c: 2\n            ```\n        \"\"\"\n        yield from dict_walk(self)\n\n    def equal_values(self, other: \"Namespace\") -&gt; bool:\n        \"\"\"\n        Compare values recursively with another namespace.\n\n        Args:\n            other: The namespace to compare against.\n\n        Returns:\n            True if all values match recursively, False otherwise.\n        \"\"\"\n        return compare(self, other)\n\n    def copy(self) -&gt; \"Namespace\":\n        \"\"\"Create a shallow copy of the namespace.\"\"\"\n        return copy(self)\n\n    def deepcopy(self) -&gt; \"Namespace\":\n        \"\"\"Create a deep copy of the namespace.\"\"\"\n        return deepcopy(self)\n\n    def to_dict(self) -&gt; Dict[str, Any]:\n        \"\"\"Convert the namespace to a regular dictionary recursively.\"\"\"\n        return to_dict(self)\n\n    def depth(self) -&gt; int:\n        \"\"\"\n        Calculate the maximum depth of nested dictionaries.\n\n        Returns:\n            The maximum nesting level, where 0 means no nesting.\n        \"\"\"\n        return depth(self)\n\n    def pformat(self):\n        return pformat(self)\n\n    def all(self):\n        return all_true(self)\n</code></pre>"},{"location":"reference/namespace/#datamate.namespaces.Namespace.__dir__","title":"__dir__","text":"<pre><code>__dir__()\n</code></pre> <p>Return list of valid attributes including dictionary keys.</p> Source code in <code>datamate/namespaces.py</code> <pre><code>def __dir__(self) -&gt; List[str]:\n    \"\"\"Return list of valid attributes including dictionary keys.\"\"\"\n    return list(set([*dict.__dir__(self), *dict.__iter__(self)]))\n</code></pre>"},{"location":"reference/namespace/#datamate.namespaces.Namespace.without","title":"without","text":"<pre><code>without(key)\n</code></pre> <p>Return a copy of the namespace without the specified key.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>Key to remove from the namespace.</p> required <p>Returns:</p> Type Description <code>Namespace</code> <p>New namespace without the specified key.</p> Source code in <code>datamate/namespaces.py</code> <pre><code>def without(self, key: str) -&gt; \"Namespace\":\n    \"\"\"\n    Return a copy of the namespace without the specified key.\n\n    Args:\n        key: Key to remove from the namespace.\n\n    Returns:\n        New namespace without the specified key.\n    \"\"\"\n    _copy = self.deepcopy()\n    _copy.pop(key)\n    return _copy\n</code></pre>"},{"location":"reference/namespace/#datamate.namespaces.Namespace.is_subset","title":"is_subset","text":"<pre><code>is_subset(other)\n</code></pre> <p>Check if this namespace is a subset of another.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>Union[Dict, Namespace]</code> <p>The potential superset to compare against.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if this namespace is a subset of other.</p> Source code in <code>datamate/namespaces.py</code> <pre><code>def is_subset(self, other: Union[Dict, \"Namespace\"]) -&gt; bool:\n    \"\"\"\n    Check if this namespace is a subset of another.\n\n    Args:\n        other: The potential superset to compare against.\n\n    Returns:\n        True if this namespace is a subset of other.\n    \"\"\"\n    return is_superset(other, self)\n</code></pre>"},{"location":"reference/namespace/#datamate.namespaces.Namespace.is_disjoint","title":"is_disjoint","text":"<pre><code>is_disjoint(other_dict)\n</code></pre> <p>Check whether another dictionary is disjoint with respect to this one.</p> <p>Two dictionaries are considered disjoint if they have no common keys.</p> <p>Parameters: other_dict (dict): The other dictionary to check for disjointness.</p> <p>bool: True if the other dictionary is disjoint with respect to this one,       False otherwise.</p> Source code in <code>datamate/namespaces.py</code> <pre><code>def is_disjoint(self, other_dict):\n    \"\"\"\n    Check whether another dictionary is disjoint with respect to this one.\n\n    Two dictionaries are considered disjoint if they have no common keys.\n\n    Parameters:\n    other_dict (dict): The other dictionary to check for disjointness.\n\n    Returns:\n    bool: True if the other dictionary is disjoint with respect to this one,\n          False otherwise.\n    \"\"\"\n    return is_disjoint(self, other_dict)\n</code></pre>"},{"location":"reference/namespace/#datamate.namespaces.Namespace.to_df","title":"to_df","text":"<pre><code>to_df(name='', seperator='.')\n</code></pre> <p>Convert namespace to flattened DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Column name for the resulting DataFrame.</p> <code>''</code> <code>seperator</code> <code>str</code> <p>Character to use for separating nested keys.</p> <code>'.'</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>Flattened DataFrame representation.</p> Source code in <code>datamate/namespaces.py</code> <pre><code>def to_df(self, name: str = \"\", seperator: str = \".\") -&gt; \"pd.DataFrame\":  # type: ignore\n    \"\"\"\n    Convert namespace to flattened DataFrame.\n\n    Args:\n        name: Column name for the resulting DataFrame.\n        seperator: Character to use for separating nested keys.\n\n    Returns:\n        Flattened DataFrame representation.\n    \"\"\"\n    as_dict = self.to_dict()  # namespace need deepcopy method\n    df = pd.json_normalize(as_dict, sep=seperator).T\n    if name:\n        df = df.rename({0: name}, axis=1)\n    return df\n</code></pre>"},{"location":"reference/namespace/#datamate.namespaces.Namespace.diff","title":"diff","text":"<pre><code>diff(other, name1='self', name2='other')\n</code></pre> <p>Compare two namespaces and return their differences.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>Namespace</code> <p>The namespace to compare against.</p> required <code>name1</code> <code>str</code> <p>Label for the current namespace in the diff output.</p> <code>'self'</code> <code>name2</code> <code>str</code> <p>Label for the other namespace in the diff output.</p> <code>'other'</code> <p>Returns:</p> Type Description <code>Namespace</code> <p>A namespace containing the differences, with + indicating additions,</p> <code>Namespace</code> <ul> <li>indicating deletions, and \u2260 indicating changes.</li> </ul> <p>Examples:</p> <pre><code>ns1 = Namespace({\"a\": 1, \"b\": 2})\nns2 = Namespace({\"b\": 3, \"c\": 4})\ndiff = ns1.diff(ns2)\n# Returns: {\n#   \"self\": [\"+a: 1\", \"\u2260b: 2\", \"-c\"],\n#   \"other\": [\"-a\", \"\u2260b: 3\", \"+c: 4\"]\n# }\n</code></pre> Source code in <code>datamate/namespaces.py</code> <pre><code>def diff(\n    self, other: \"Namespace\", name1: str = \"self\", name2: str = \"other\"\n) -&gt; \"Namespace\":\n    \"\"\"\n    Compare two namespaces and return their differences.\n\n    Args:\n        other: The namespace to compare against.\n        name1: Label for the current namespace in the diff output.\n        name2: Label for the other namespace in the diff output.\n\n    Returns:\n        A namespace containing the differences, with + indicating additions,\n        - indicating deletions, and \u2260 indicating changes.\n\n    Examples:\n        ```python\n        ns1 = Namespace({\"a\": 1, \"b\": 2})\n        ns2 = Namespace({\"b\": 3, \"c\": 4})\n        diff = ns1.diff(ns2)\n        # Returns: {\n        #   \"self\": [\"+a: 1\", \"\u2260b: 2\", \"-c\"],\n        #   \"other\": [\"-a\", \"\u2260b: 3\", \"+c: 4\"]\n        # }\n        ```\n    \"\"\"\n    if self is None or other is None:\n        return Namespace({name1: self, name2: other})\n\n    _self = namespacify(self)\n    other = namespacify(other)\n    diff1: List[str] = []\n    diff2: List[str] = []\n    diff = {name1: diff1, name2: diff2}\n\n    def _diff(self: Namespace, other: Namespace, parent: str = \"\") -&gt; None:\n        for k, v in self.items():\n            if k not in other:\n                _diff1 = f\"+{parent}.{k}: {v}\" if parent else f\"+{k}: {v}\"\n                _diff2 = f\"-{parent}.{k}\" if parent else f\"-{k}\"\n                diff1.append(_diff1)\n                diff2.append(_diff2)\n            elif v == other[k]:\n                pass\n            elif isinstance(v, Namespace):\n                _parent = f\"{parent}.{k}\" if parent else f\"{k}\"\n                _diff(v, other[k], parent=_parent)\n            else:\n                _diff1 = f\"\u2260{parent}.{k}: {v}\" if parent else f\"\u2260{k}: {v}\"\n                _diff2 = (\n                    f\"\u2260{parent}.{k}: {other[k]}\" if parent else f\"\u2260{k}: {other[k]}\"\n                )\n                diff1.append(_diff1)\n                diff2.append(_diff2)\n\n        for k, v in other.items():\n            if k not in self:\n                _diff1 = f\"-{parent}.{k}\" if parent else f\"-{k}\"\n                _diff2 = f\"+{parent}.{k}: {v}\" if parent else f\"+{k}: {v}\"\n                diff1.append(_diff1)\n                diff2.append(_diff2)\n\n    _diff(_self, other)\n    return namespacify(diff)\n</code></pre>"},{"location":"reference/namespace/#datamate.namespaces.Namespace.walk","title":"walk","text":"<pre><code>walk()\n</code></pre> <p>Recursively walk through the namespace and yield key-value pairs.</p> <p>Yields:</p> Type Description <code>Tuple[str, Any]</code> <p>Tuples of (key, value) for each item in the namespace, including nested items.</p> <p>Examples:</p> <pre><code>ns = Namespace({\"a\": 1, \"b\": {\"c\": 2}})\nfor key, value in ns.walk():\n    print(f\"{key}: {value}\")\n# Prints:\n# a: 1\n# b: {'c': 2}\n# c: 2\n</code></pre> Source code in <code>datamate/namespaces.py</code> <pre><code>def walk(self) -&gt; Iterator[Tuple[str, Any]]:\n    \"\"\"\n    Recursively walk through the namespace and yield key-value pairs.\n\n    Yields:\n        Tuples of (key, value) for each item in the namespace, including nested items.\n\n    Examples:\n        ```python\n        ns = Namespace({\"a\": 1, \"b\": {\"c\": 2}})\n        for key, value in ns.walk():\n            print(f\"{key}: {value}\")\n        # Prints:\n        # a: 1\n        # b: {'c': 2}\n        # c: 2\n        ```\n    \"\"\"\n    yield from dict_walk(self)\n</code></pre>"},{"location":"reference/namespace/#datamate.namespaces.Namespace.equal_values","title":"equal_values","text":"<pre><code>equal_values(other)\n</code></pre> <p>Compare values recursively with another namespace.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>Namespace</code> <p>The namespace to compare against.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if all values match recursively, False otherwise.</p> Source code in <code>datamate/namespaces.py</code> <pre><code>def equal_values(self, other: \"Namespace\") -&gt; bool:\n    \"\"\"\n    Compare values recursively with another namespace.\n\n    Args:\n        other: The namespace to compare against.\n\n    Returns:\n        True if all values match recursively, False otherwise.\n    \"\"\"\n    return compare(self, other)\n</code></pre>"},{"location":"reference/namespace/#datamate.namespaces.Namespace.copy","title":"copy","text":"<pre><code>copy()\n</code></pre> <p>Create a shallow copy of the namespace.</p> Source code in <code>datamate/namespaces.py</code> <pre><code>def copy(self) -&gt; \"Namespace\":\n    \"\"\"Create a shallow copy of the namespace.\"\"\"\n    return copy(self)\n</code></pre>"},{"location":"reference/namespace/#datamate.namespaces.Namespace.deepcopy","title":"deepcopy","text":"<pre><code>deepcopy()\n</code></pre> <p>Create a deep copy of the namespace.</p> Source code in <code>datamate/namespaces.py</code> <pre><code>def deepcopy(self) -&gt; \"Namespace\":\n    \"\"\"Create a deep copy of the namespace.\"\"\"\n    return deepcopy(self)\n</code></pre>"},{"location":"reference/namespace/#datamate.namespaces.Namespace.to_dict","title":"to_dict","text":"<pre><code>to_dict()\n</code></pre> <p>Convert the namespace to a regular dictionary recursively.</p> Source code in <code>datamate/namespaces.py</code> <pre><code>def to_dict(self) -&gt; Dict[str, Any]:\n    \"\"\"Convert the namespace to a regular dictionary recursively.\"\"\"\n    return to_dict(self)\n</code></pre>"},{"location":"reference/namespace/#datamate.namespaces.Namespace.depth","title":"depth","text":"<pre><code>depth()\n</code></pre> <p>Calculate the maximum depth of nested dictionaries.</p> <p>Returns:</p> Type Description <code>int</code> <p>The maximum nesting level, where 0 means no nesting.</p> Source code in <code>datamate/namespaces.py</code> <pre><code>def depth(self) -&gt; int:\n    \"\"\"\n    Calculate the maximum depth of nested dictionaries.\n\n    Returns:\n        The maximum nesting level, where 0 means no nesting.\n    \"\"\"\n    return depth(self)\n</code></pre>"},{"location":"reference/namespace/#datamate.namespaces.namespacify","title":"namespacify","text":"<pre><code>namespacify(obj)\n</code></pre> <p>Recursively convert mappings and ad-hoc Namespaces to <code>Namespace</code> objects.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>object</code> <p>The object to convert into a Namespace.</p> required <p>Returns:</p> Type Description <code>Namespace</code> <p>A new Namespace object with both item and attribute access.</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If the object cannot be converted to a Namespace.</p> <p>Examples:</p> <pre><code>class MyClass:\n    def __init__(self):\n        self.a = 1\n        self.b = {\"c\": 2}\n\nobj = MyClass()\nns = namespacify(obj)\nassert ns.a == 1\nassert ns.b.c == 2\n</code></pre> Source code in <code>datamate/namespaces.py</code> <pre><code>def namespacify(obj: object) -&gt; Namespace:\n    \"\"\"\n    Recursively convert mappings and ad-hoc Namespaces to `Namespace` objects.\n\n    Args:\n        obj: The object to convert into a Namespace.\n\n    Returns:\n        A new Namespace object with both item and attribute access.\n\n    Raises:\n        TypeError: If the object cannot be converted to a Namespace.\n\n    Examples:\n        ```python\n        class MyClass:\n            def __init__(self):\n                self.a = 1\n                self.b = {\"c\": 2}\n\n        obj = MyClass()\n        ns = namespacify(obj)\n        assert ns.a == 1\n        assert ns.b.c == 2\n        ```\n    \"\"\"\n    if isinstance(obj, (type(None), bool, int, float, str, type, bytes)):\n        return obj\n    elif isinstance(obj, Path):\n        return str(obj)\n    elif isinstance(obj, (list, tuple)):\n        return [namespacify(v) for v in obj]\n    elif isinstance(obj, (ndarray)):\n        return [namespacify(v.item()) for v in obj]\n    elif isinstance(obj, Mapping):\n        return Namespace({k: namespacify(obj[k]) for k in obj})\n    elif get_origin(obj) is not None:\n        return obj\n    else:\n        try:\n            return namespacify(vars(obj))\n        except TypeError as e:\n            raise TypeError(f\"namespacifying {obj} of type {type(obj)}: {e}.\") from e\n</code></pre>"},{"location":"reference/namespace/#datamate.namespaces.is_subset","title":"is_subset","text":"<pre><code>is_subset(dict1, dict2)\n</code></pre> <p>Check whether dict2 is a subset of dict1.</p> <p>Parameters:</p> Name Type Description Default <code>dict1</code> <code>Union[Dict, Namespace]</code> <p>The superset dictionary.</p> required <code>dict2</code> <code>Union[Dict, Namespace]</code> <p>The subset dictionary.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if dict2 is a subset of dict1, False otherwise.</p> <p>Examples:</p> <pre><code>d1 = {\"a\": 1, \"b\": {\"c\": 2, \"d\": 3}}\nd2 = {\"b\": {\"c\": 2}}\nassert is_subset(d1, d2) == True\n</code></pre> Source code in <code>datamate/namespaces.py</code> <pre><code>def is_subset(dict1: Union[Dict, Namespace], dict2: Union[Dict, Namespace]) -&gt; bool:\n    \"\"\"\n    Check whether dict2 is a subset of dict1.\n\n    Args:\n        dict1: The superset dictionary.\n        dict2: The subset dictionary.\n\n    Returns:\n        True if dict2 is a subset of dict1, False otherwise.\n\n    Examples:\n        ```python\n        d1 = {\"a\": 1, \"b\": {\"c\": 2, \"d\": 3}}\n        d2 = {\"b\": {\"c\": 2}}\n        assert is_subset(d1, d2) == True\n        ```\n    \"\"\"\n    for key, value in dict2.items():\n        if key not in dict1:\n            return False\n        if isinstance(value, dict):\n            if not is_subset(dict1[key], value):\n                return False\n        else:\n            if dict1[key] != value:\n                return False\n    return True\n</code></pre>"},{"location":"reference/namespace/#datamate.namespaces.is_superset","title":"is_superset","text":"<pre><code>is_superset(dict1, dict2)\n</code></pre> <p>Check whether dict2 is a superset of dict1.</p> <p>Parameters:</p> Name Type Description Default <code>dict1</code> <code>Union[Dict, Namespace]</code> <p>The subset dictionary.</p> required <code>dict2</code> <code>Union[Dict, Namespace]</code> <p>The superset dictionary.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if dict2 is a superset of dict1, False otherwise.</p> Source code in <code>datamate/namespaces.py</code> <pre><code>def is_superset(dict1: Union[Dict, Namespace], dict2: Union[Dict, Namespace]) -&gt; bool:\n    \"\"\"\n    Check whether dict2 is a superset of dict1.\n\n    Args:\n        dict1: The subset dictionary.\n        dict2: The superset dictionary.\n\n    Returns:\n        True if dict2 is a superset of dict1, False otherwise.\n    \"\"\"\n    return is_subset(dict2, dict1)\n</code></pre>"},{"location":"reference/namespace/#datamate.namespaces.is_disjoint","title":"is_disjoint","text":"<pre><code>is_disjoint(dict1, dict2)\n</code></pre> <p>Check whether two dictionaries are disjoint.</p> <p>Parameters:</p> Name Type Description Default <code>dict1</code> <code>Union[Dict, Namespace]</code> <p>First dictionary to compare.</p> required <code>dict2</code> <code>Union[Dict, Namespace]</code> <p>Second dictionary to compare.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the dictionaries have no common keys at any nesting level.</p> <p>Examples:</p> <pre><code>d1 = {\"a\": 1, \"b\": {\"c\": 2}}\nd2 = {\"d\": 3, \"e\": {\"f\": 4}}\nassert is_disjoint(d1, d2) == True\n</code></pre> Source code in <code>datamate/namespaces.py</code> <pre><code>def is_disjoint(dict1: Union[Dict, Namespace], dict2: Union[Dict, Namespace]) -&gt; bool:\n    \"\"\"\n    Check whether two dictionaries are disjoint.\n\n    Args:\n        dict1: First dictionary to compare.\n        dict2: Second dictionary to compare.\n\n    Returns:\n        True if the dictionaries have no common keys at any nesting level.\n\n    Examples:\n        ```python\n        d1 = {\"a\": 1, \"b\": {\"c\": 2}}\n        d2 = {\"d\": 3, \"e\": {\"f\": 4}}\n        assert is_disjoint(d1, d2) == True\n        ```\n    \"\"\"\n    dict1_keys = set(key for key, _ in dict_walk(dict1))\n    dict2_keys = set(key for key, _ in dict_walk(dict2))\n    return dict1_keys.isdisjoint(dict2_keys)\n</code></pre>"},{"location":"reference/namespace/#datamate.namespaces.to_dict","title":"to_dict","text":"<pre><code>to_dict(obj)\n</code></pre> <p>Convert a Namespace or nested structure to a regular dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>Any</code> <p>Object to convert to a dictionary.</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>A dictionary representation of the input object.</p> Source code in <code>datamate/namespaces.py</code> <pre><code>def to_dict(obj: Any) -&gt; Dict[str, Any]:\n    \"\"\"\n    Convert a Namespace or nested structure to a regular dictionary.\n\n    Args:\n        obj: Object to convert to a dictionary.\n\n    Returns:\n        A dictionary representation of the input object.\n    \"\"\"\n    if isinstance(obj, dict):\n        return dict((k, to_dict(v)) for k, v in obj.items())\n    if isinstance(obj, list):\n        return [to_dict(v) for v in obj]\n    elif isinstance(obj, Namespace):\n        return dict((k, to_dict(v)) for k, v in obj.items())\n    else:\n        return obj\n</code></pre>"},{"location":"reference/namespace/#datamate.namespaces.depth","title":"depth","text":"<pre><code>depth(obj)\n</code></pre> <p>Calculate the maximum depth of nested dictionaries.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>Union[Dict, Namespace]</code> <p>Dictionary or Namespace to measure depth of.</p> required <p>Returns:</p> Type Description <code>int</code> <p>Maximum nesting level, where 0 means no nesting.</p> <p>Examples:</p> <pre><code>d = {\"a\": 1, \"b\": {\"c\": {\"d\": 2}}}\nassert depth(d) == 3\n</code></pre> Source code in <code>datamate/namespaces.py</code> <pre><code>def depth(obj: Union[Dict, Namespace]) -&gt; int:\n    \"\"\"\n    Calculate the maximum depth of nested dictionaries.\n\n    Args:\n        obj: Dictionary or Namespace to measure depth of.\n\n    Returns:\n        Maximum nesting level, where 0 means no nesting.\n\n    Examples:\n        ```python\n        d = {\"a\": 1, \"b\": {\"c\": {\"d\": 2}}}\n        assert depth(d) == 3\n        ```\n    \"\"\"\n    if isinstance(obj, (dict, Namespace)):\n        return 1 + (max(map(depth, obj.values())) if obj else 0)\n    return 0\n</code></pre>"},{"location":"reference/namespace/#datamate.namespaces.pformat","title":"pformat","text":"<pre><code>pformat(obj)\n</code></pre> <p>Pretty format a Namespace or dictionary for display.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>Any</code> <p>Object to format.</p> required <p>Returns:</p> Type Description <code>str</code> <p>String representation of the object with proper indentation.</p> Source code in <code>datamate/namespaces.py</code> <pre><code>def pformat(obj: Any) -&gt; str:\n    \"\"\"\n    Pretty format a Namespace or dictionary for display.\n\n    Args:\n        obj: Object to format.\n\n    Returns:\n        String representation of the object with proper indentation.\n    \"\"\"\n    import pprint\n\n    pretty_printer = pprint.PrettyPrinter(depth=100)\n    return pretty_printer.pformat(obj)\n</code></pre>"},{"location":"reference/namespace/#datamate.namespaces.compare","title":"compare","text":"<pre><code>compare(obj1, obj2)\n</code></pre> <p>Type agnostic comparison for basic types and nested dictionaries.</p> <p>Parameters:</p> Name Type Description Default <code>obj1</code> <code>Any</code> <p>First object to compare.</p> required <code>obj2</code> <code>Any</code> <p>Second object to compare.</p> required <p>Returns:</p> Type Description <code>Union[bool, Namespace]</code> <p>Boolean for simple types, Namespace of comparison results for complex types.</p> <p>Examples:</p> <pre><code>ns1 = Namespace({\"a\": 1, \"b\": {\"c\": 2}})\nns2 = Namespace({\"a\": 1, \"b\": {\"c\": 3}})\nresult = compare(ns1, ns2)\nassert result.a == True\nassert result.b.c == False\n</code></pre> Source code in <code>datamate/namespaces.py</code> <pre><code>def compare(obj1: Any, obj2: Any) -&gt; Union[bool, \"Namespace\"]:\n    \"\"\"\n    Type agnostic comparison for basic types and nested dictionaries.\n\n    Args:\n        obj1: First object to compare.\n        obj2: Second object to compare.\n\n    Returns:\n        Boolean for simple types, Namespace of comparison results for complex types.\n\n    Examples:\n        ```python\n        ns1 = Namespace({\"a\": 1, \"b\": {\"c\": 2}})\n        ns2 = Namespace({\"a\": 1, \"b\": {\"c\": 3}})\n        result = compare(ns1, ns2)\n        assert result.a == True\n        assert result.b.c == False\n        ```\n    \"\"\"\n    if isinstance(obj1, (type(None), bool, int, float, str, type)) and isinstance(\n        obj2, (type(None), bool, int, float, str, type)\n    ):\n        return obj1 == obj2\n    elif isinstance(obj1, (list, tuple)) and isinstance(obj2, (list, tuple)):\n        return False if len(obj1) != len(obj2) else obj1 == obj2\n    elif isinstance(obj1, (ndarray)) and isinstance(obj2, (ndarray)):\n        return compare(obj1.tolist(), obj2.tolist())\n    elif isinstance(obj1, Mapping) and isinstance(obj2, Mapping):\n        _obj1, _obj2 = obj1.deepcopy(), obj2.deepcopy()\n        out = {}\n        for key in (\n            set(_obj1.keys())\n            .difference(set(_obj2.keys()))\n            .union(set(_obj2.keys()).difference(set(_obj1.keys())))\n        ):\n            out[key] = False\n            _obj1.pop(key, None)\n            _obj2.pop(key, None)\n        for k in _obj1:\n            out[k] = compare(_obj1[k], obj2[k])\n        return Namespace(out)\n    elif not isinstance(obj1, type(obj2)):\n        return False\n</code></pre>"},{"location":"reference/namespace/#datamate.namespaces.all_true","title":"all_true","text":"<pre><code>all_true(obj)\n</code></pre> <p>Check if all elements in a nested structure evaluate to True.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>Any</code> <p>Object to evaluate, can be nested structure.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if bool(element) is True for all elements in nested obj.</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If object cannot be evaluated.</p> <p>Examples:</p> <pre><code>ns = Namespace({\"a\": True, \"b\": {\"c\": 1, \"d\": \"text\"}})\nassert all_true(ns) == True\n</code></pre> Source code in <code>datamate/namespaces.py</code> <pre><code>def all_true(obj: Any) -&gt; bool:\n    \"\"\"\n    Check if all elements in a nested structure evaluate to True.\n\n    Args:\n        obj: Object to evaluate, can be nested structure.\n\n    Returns:\n        True if bool(element) is True for all elements in nested obj.\n\n    Raises:\n        TypeError: If object cannot be evaluated.\n\n    Examples:\n        ```python\n        ns = Namespace({\"a\": True, \"b\": {\"c\": 1, \"d\": \"text\"}})\n        assert all_true(ns) == True\n        ```\n    \"\"\"\n    if isinstance(obj, (type(None), bool, int, float, str, type, bytes)):\n        return bool(obj)\n    elif isinstance(obj, Path):\n        return bool(obj)\n    elif isinstance(obj, (list, tuple)):\n        return all([all_true(v) for v in obj])\n    elif isinstance(obj, (ndarray)):\n        return all([all_true(v.item()) for v in obj])\n    elif isinstance(obj, Mapping):\n        return all([all_true(obj[k]) for k in obj])\n    else:\n        try:\n            return all_true(vars(obj))\n        except TypeError as e:\n            raise TypeError(f\"all {obj} of type {type(obj)}: {e}.\") from e\n</code></pre>"},{"location":"reference/namespace/#datamate.namespaces.dict_walk","title":"dict_walk","text":"<pre><code>dict_walk(dictionary)\n</code></pre> <p>Recursively walk through a nested dictionary and yield key-value pairs.</p> <p>Parameters:</p> Name Type Description Default <code>dictionary</code> <code>Union[Dict, Namespace]</code> <p>Dictionary or Namespace to traverse.</p> required <p>Yields:</p> Type Description <code>Tuple[str, Any]</code> <p>Tuple of (key, value) for each item, including nested items.</p> <p>Examples:</p> <pre><code>d = {\"a\": 1, \"b\": {\"c\": 2}}\nfor key, value in dict_walk(d):\n    print(f\"{key}: {value}\")\n# Prints:\n# a: 1\n# b: {'c': 2}\n# c: 2\n</code></pre> Source code in <code>datamate/namespaces.py</code> <pre><code>def dict_walk(dictionary: Union[Dict, Namespace]) -&gt; Iterator[Tuple[str, Any]]:\n    \"\"\"\n    Recursively walk through a nested dictionary and yield key-value pairs.\n\n    Args:\n        dictionary: Dictionary or Namespace to traverse.\n\n    Yields:\n        Tuple of (key, value) for each item, including nested items.\n\n    Examples:\n        ```python\n        d = {\"a\": 1, \"b\": {\"c\": 2}}\n        for key, value in dict_walk(d):\n            print(f\"{key}: {value}\")\n        # Prints:\n        # a: 1\n        # b: {'c': 2}\n        # c: 2\n        ```\n    \"\"\"\n    for key, value in dictionary.items():\n        yield (key, value)\n        if isinstance(value, dict):\n            yield from dict_walk(value)\n</code></pre>"},{"location":"reference/utils/","title":"Utils","text":""},{"location":"reference/utils/#datamate.utils","title":"datamate.utils","text":"<p>Utility functions for Directory objects.</p>"},{"location":"reference/utils/#datamate.utils.check_size","title":"check_size","text":"<pre><code>check_size(\n    path, warning_at=20 * 1024**3, print_size=False\n)\n</code></pre> <p>Check and optionally print directory size, warning if it exceeds threshold.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>Directory path to check.</p> required <code>warning_at</code> <code>int</code> <p>Size threshold in bytes to trigger warning.</p> <code>20 * 1024 ** 3</code> <code>print_size</code> <code>bool</code> <p>Whether to print the directory size.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>Size of directory in bytes.</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If path doesn\u2019t exist.</p> Source code in <code>datamate/utils.py</code> <pre><code>def check_size(\n    path: Path, warning_at: int = 20 * 1024**3, print_size: bool = False\n) -&gt; int:\n    \"\"\"Check and optionally print directory size, warning if it exceeds threshold.\n\n    Args:\n        path: Directory path to check.\n        warning_at: Size threshold in bytes to trigger warning.\n        print_size: Whether to print the directory size.\n\n    Returns:\n        int: Size of directory in bytes.\n\n    Raises:\n        FileNotFoundError: If path doesn't exist.\n    \"\"\"\n\n    def sizeof_fmt(num: float, suffix: str = \"B\") -&gt; str:\n        for unit in [\"\", \"Ki\", \"Mi\", \"Gi\", \"Ti\", \"Pi\", \"Ei\", \"Zi\"]:\n            if abs(num) &lt; 1024.0:\n                return f\"{num:3.1f}{unit}{suffix}\"\n            num /= 1024.0\n        return f\"{num:.1f}Yi{suffix}\"\n\n    def get_size(start_path: Path) -&gt; int:\n        total_size = 0\n        for dirpath, _, filenames in os.walk(start_path):\n            for f in filenames:\n                fp = os.path.join(dirpath, f)\n                if not os.path.islink(fp):\n                    with contextlib.suppress(FileNotFoundError):\n                        total_size += os.path.getsize(fp)\n        return total_size\n\n    size_in_bytes = get_size(path)\n    if print_size:\n        print(f\"{sizeof_fmt(size_in_bytes)}\")\n    if size_in_bytes &gt;= warning_at:\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"always\")\n            warnings.warn(\n                f\"This directory {path.name} occupies {sizeof_fmt(size_in_bytes)} \"\n                + \"of disk space.\",\n                ResourceWarning,\n                stacklevel=2,\n            )\n    return size_in_bytes\n</code></pre>"},{"location":"reference/utils/#datamate.utils.tree","title":"tree","text":"<pre><code>tree(\n    dir_path,\n    level=-1,\n    limit_to_directories=False,\n    length_limit=1000,\n    last_modified=False,\n    not_exists_message=\"path does not exist\",\n    permission_denied_message=\"permission denied\",\n    verbose=True,\n)\n</code></pre> <p>Generate a visual tree structure of a directory.</p> <p>Parameters:</p> Name Type Description Default <code>dir_path</code> <code>Path</code> <p>Root directory to start tree from.</p> required <code>level</code> <code>int</code> <p>Maximum depth to traverse (-1 for unlimited).</p> <code>-1</code> <code>limit_to_directories</code> <code>bool</code> <p>Only show directories, not files.</p> <code>False</code> <code>length_limit</code> <code>int</code> <p>Maximum number of lines to output.</p> <code>1000</code> <code>last_modified</code> <code>bool</code> <p>Show last modification time of root directory.</p> <code>False</code> <code>not_exists_message</code> <code>str</code> <p>Message to show when path doesn\u2019t exist.</p> <code>'path does not exist'</code> <code>permission_denied_message</code> <code>str</code> <p>Message to show when permission is denied.</p> <code>'permission denied'</code> <code>verbose</code> <code>bool</code> <p>Include summary statistics in output.</p> <code>True</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Formatted tree structure as string.</p> Example <pre><code>print(tree(Path(\"./my_directory\"), level=2))\n</code></pre> <p>Based on: https://stackoverflow.com/a/59109706</p> Source code in <code>datamate/utils.py</code> <pre><code>def tree(\n    dir_path: Path,\n    level: int = -1,\n    limit_to_directories: bool = False,\n    length_limit: int = 1000,\n    last_modified: bool = False,\n    not_exists_message: str = \"path does not exist\",\n    permission_denied_message: str = \"permission denied\",\n    verbose: bool = True,\n) -&gt; str:\n    \"\"\"Generate a visual tree structure of a directory.\n\n    Args:\n        dir_path: Root directory to start tree from.\n        level: Maximum depth to traverse (-1 for unlimited).\n        limit_to_directories: Only show directories, not files.\n        length_limit: Maximum number of lines to output.\n        last_modified: Show last modification time of root directory.\n        not_exists_message: Message to show when path doesn't exist.\n        permission_denied_message: Message to show when permission is denied.\n        verbose: Include summary statistics in output.\n\n    Returns:\n        str: Formatted tree structure as string.\n\n    Example:\n        ```python\n        print(tree(Path(\"./my_directory\"), level=2))\n        ```\n\n    Based on: https://stackoverflow.com/a/59109706\n    \"\"\"\n    # prefix components:\n    space = \"    \"\n    branch = \"\u2502   \"\n    # pointers:\n    tee = \"\u251c\u2500\u2500 \"\n    last = \"\u2514\u2500\u2500 \"\n\n    tree_string = \"\"\n\n    dir_path = Path(dir_path)  # accept string coerceable to Path\n    files = 0\n    directories = 1\n\n    def inner(dir_path: Path, prefix: str = \"\", level=-1):\n        nonlocal files, directories\n        if not level:\n            yield prefix + \"...\"\n            return  # 0, stop iterating\n        try:\n            if limit_to_directories:\n                contents = sorted([d for d in dir_path.iterdir() if d.is_dir()])\n            else:\n                contents = sorted(dir_path.iterdir())\n        except PermissionError as e:\n            if \"[Errno 1]\" in str(e):\n                contents = [f\"({permission_denied_message})\"]\n\n        pointers = [tee] * (len(contents) - 1) + [last]\n        for pointer, path in zip(pointers, contents):\n            if isinstance(path, Path):\n                if path.is_dir():\n                    yield prefix + pointer + path.name + \"/\"\n                    directories += 1\n                    extension = branch if pointer == tee else space\n                    yield from inner(path, prefix=prefix + extension, level=level - 1)\n                elif not limit_to_directories:\n                    yield prefix + pointer + path.name\n                    files += 1\n            else:\n                assert path == f\"({permission_denied_message})\"\n                yield prefix + pointer + path\n\n    tree_string += dir_path.name + \"/\"\n\n    if not dir_path.exists():\n        tree_string += f\"\\n{space}({not_exists_message})\"\n        return tree_string\n\n    if last_modified:\n        timestamp = datetime.datetime.fromtimestamp(dir_path.stat().st_mtime)\n        mtime = \" - Last modified: {}\".format(timestamp.strftime(\"%B %d, %Y %H:%M:%S\"))\n        tree_string += mtime\n    tree_string += \"\\n\"\n    iterator = inner(dir_path, level=level)\n    for line in itertools.islice(iterator, length_limit):\n        tree_string += line + \"\\n\"\n\n    if verbose:\n        if next(iterator, None):\n            tree_string += f\"... length_limit, {length_limit}, reached,\"\n        tree_string += (\n            f\"\\ndisplaying: {directories} {'directory' if directories == 1 else 'directories'}\"  # noqa: E501\n            + (f\", {files} files\" if files else \"\")\n            + (f\", {level} levels.\" if level &gt;= 1 else \"\")\n        )\n\n    return tree_string\n</code></pre>"},{"location":"reference/utils/#datamate.utils.byte_to_str","title":"byte_to_str","text":"<pre><code>byte_to_str(obj)\n</code></pre> <p>Convert byte elements to string types recursively.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>Union[Mapping, ndarray, list, tuple, bytes, str, Number]</code> <p>Object to convert, can be nested structure containing bytes.</p> required <p>Returns:</p> Type Description <code>Union[Mapping, ndarray, list, tuple, str, Number]</code> <p>Converted object with bytes decoded to strings.</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If object type cannot be converted.</p> Note <p>Function recursively processes nested lists and tuples.</p> Source code in <code>datamate/utils.py</code> <pre><code>def byte_to_str(\n    obj: Union[Mapping, np.ndarray, list, tuple, bytes, str, Number],\n) -&gt; Union[Mapping, np.ndarray, list, tuple, str, Number]:\n    \"\"\"Convert byte elements to string types recursively.\n\n    Args:\n        obj: Object to convert, can be nested structure containing bytes.\n\n    Returns:\n        Converted object with bytes decoded to strings.\n\n    Raises:\n        TypeError: If object type cannot be converted.\n\n    Note:\n        Function recursively processes nested lists and tuples.\n    \"\"\"\n    if isinstance(obj, Mapping):\n        return type(obj)({k: byte_to_str(v) for k, v in obj.items()})\n    elif isinstance(obj, np.ndarray):\n        if np.issubdtype(obj.dtype, np.dtype(\"S\")):\n            return obj.astype(\"U\")\n        return obj\n    elif isinstance(obj, list):\n        return [byte_to_str(item) for item in obj]\n    elif isinstance(obj, tuple):\n        return tuple(byte_to_str(item) for item in obj)\n    elif isinstance(obj, bytes):\n        return obj.decode()\n    elif isinstance(obj, (str, Number)):\n        return obj\n    else:\n        raise TypeError(f\"can't cast {obj} of type {type(obj)} to str\")\n</code></pre>"}]}